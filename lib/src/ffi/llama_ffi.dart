// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// FFI bindings to llama.cpp C API
class llama_cpp {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
  _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  llama_cpp(ffi.DynamicLibrary dynamicLibrary)
    : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  llama_cpp.fromLookup(
    ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName) lookup,
  ) : _lookup = lookup;

  ffi.Pointer<ffi.Char> llama_flash_attn_type_name(
    llama_flash_attn_type flash_attn_type,
  ) {
    return _llama_flash_attn_type_name(flash_attn_type.value);
  }

  late final _llama_flash_attn_type_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
        'llama_flash_attn_type_name',
      );
  late final _llama_flash_attn_type_name = _llama_flash_attn_type_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  llama_model_params llama_model_default_params() {
    return _llama_model_default_params();
  }

  late final _llama_model_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_model_params Function()>>(
        'llama_model_default_params',
      );
  late final _llama_model_default_params = _llama_model_default_paramsPtr
      .asFunction<llama_model_params Function()>();

  llama_context_params llama_context_default_params() {
    return _llama_context_default_params();
  }

  late final _llama_context_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_context_params Function()>>(
        'llama_context_default_params',
      );
  late final _llama_context_default_params = _llama_context_default_paramsPtr
      .asFunction<llama_context_params Function()>();

  llama_sampler_chain_params llama_sampler_chain_default_params() {
    return _llama_sampler_chain_default_params();
  }

  late final _llama_sampler_chain_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_sampler_chain_params Function()>>(
        'llama_sampler_chain_default_params',
      );
  late final _llama_sampler_chain_default_params =
      _llama_sampler_chain_default_paramsPtr
          .asFunction<llama_sampler_chain_params Function()>();

  llama_model_quantize_params llama_model_quantize_default_params() {
    return _llama_model_quantize_default_params();
  }

  late final _llama_model_quantize_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_model_quantize_params Function()>>(
        'llama_model_quantize_default_params',
      );
  late final _llama_model_quantize_default_params =
      _llama_model_quantize_default_paramsPtr
          .asFunction<llama_model_quantize_params Function()>();

  void llama_backend_init() {
    return _llama_backend_init();
  }

  late final _llama_backend_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('llama_backend_init');
  late final _llama_backend_init = _llama_backend_initPtr
      .asFunction<void Function()>();

  void llama_backend_free() {
    return _llama_backend_free();
  }

  late final _llama_backend_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('llama_backend_free');
  late final _llama_backend_free = _llama_backend_freePtr
      .asFunction<void Function()>();

  void llama_numa_init(ggml_numa_strategy numa) {
    return _llama_numa_init(numa.value);
  }

  late final _llama_numa_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.UnsignedInt)>>(
        'llama_numa_init',
      );
  late final _llama_numa_init = _llama_numa_initPtr
      .asFunction<void Function(int)>();

  void llama_attach_threadpool(
    ffi.Pointer<llama_context> ctx,
    ggml_threadpool_t threadpool,
    ggml_threadpool_t threadpool_batch,
  ) {
    return _llama_attach_threadpool(ctx, threadpool, threadpool_batch);
  }

  late final _llama_attach_threadpoolPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_context>,
            ggml_threadpool_t,
            ggml_threadpool_t,
          )
        >
      >('llama_attach_threadpool');
  late final _llama_attach_threadpool = _llama_attach_threadpoolPtr
      .asFunction<
        void Function(
          ffi.Pointer<llama_context>,
          ggml_threadpool_t,
          ggml_threadpool_t,
        )
      >();

  void llama_detach_threadpool(ffi.Pointer<llama_context> ctx) {
    return _llama_detach_threadpool(ctx);
  }

  late final _llama_detach_threadpoolPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_detach_threadpool');
  late final _llama_detach_threadpool = _llama_detach_threadpoolPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<llama_model> llama_load_model_from_file(
    ffi.Pointer<ffi.Char> path_model,
    llama_model_params params,
  ) {
    return _llama_load_model_from_file(path_model, params);
  }

  late final _llama_load_model_from_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(
            ffi.Pointer<ffi.Char>,
            llama_model_params,
          )
        >
      >('llama_load_model_from_file');
  late final _llama_load_model_from_file = _llama_load_model_from_filePtr
      .asFunction<
        ffi.Pointer<llama_model> Function(
          ffi.Pointer<ffi.Char>,
          llama_model_params,
        )
      >();

  ffi.Pointer<llama_model> llama_model_load_from_file(
    ffi.Pointer<ffi.Char> path_model,
    llama_model_params params,
  ) {
    return _llama_model_load_from_file(path_model, params);
  }

  late final _llama_model_load_from_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(
            ffi.Pointer<ffi.Char>,
            llama_model_params,
          )
        >
      >('llama_model_load_from_file');
  late final _llama_model_load_from_file = _llama_model_load_from_filePtr
      .asFunction<
        ffi.Pointer<llama_model> Function(
          ffi.Pointer<ffi.Char>,
          llama_model_params,
        )
      >();

  ffi.Pointer<llama_model> llama_model_load_from_splits(
    ffi.Pointer<ffi.Pointer<ffi.Char>> paths,
    int n_paths,
    llama_model_params params,
  ) {
    return _llama_model_load_from_splits(paths, n_paths, params);
  }

  late final _llama_model_load_from_splitsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Size,
            llama_model_params,
          )
        >
      >('llama_model_load_from_splits');
  late final _llama_model_load_from_splits = _llama_model_load_from_splitsPtr
      .asFunction<
        ffi.Pointer<llama_model> Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          int,
          llama_model_params,
        )
      >();

  void llama_model_save_to_file(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> path_model,
  ) {
    return _llama_model_save_to_file(model, path_model);
  }

  late final _llama_model_save_to_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>)
        >
      >('llama_model_save_to_file');
  late final _llama_model_save_to_file = _llama_model_save_to_filePtr
      .asFunction<
        void Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>)
      >();

  void llama_free_model(ffi.Pointer<llama_model> model) {
    return _llama_free_model(model);
  }

  late final _llama_free_modelPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_model>)>>(
        'llama_free_model',
      );
  late final _llama_free_model = _llama_free_modelPtr
      .asFunction<void Function(ffi.Pointer<llama_model>)>();

  void llama_model_free(ffi.Pointer<llama_model> model) {
    return _llama_model_free(model);
  }

  late final _llama_model_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_model>)>>(
        'llama_model_free',
      );
  late final _llama_model_free = _llama_model_freePtr
      .asFunction<void Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<llama_context> llama_init_from_model(
    ffi.Pointer<llama_model> model,
    llama_context_params params,
  ) {
    return _llama_init_from_model(model, params);
  }

  late final _llama_init_from_modelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_context> Function(
            ffi.Pointer<llama_model>,
            llama_context_params,
          )
        >
      >('llama_init_from_model');
  late final _llama_init_from_model = _llama_init_from_modelPtr
      .asFunction<
        ffi.Pointer<llama_context> Function(
          ffi.Pointer<llama_model>,
          llama_context_params,
        )
      >();

  ffi.Pointer<llama_context> llama_new_context_with_model(
    ffi.Pointer<llama_model> model,
    llama_context_params params,
  ) {
    return _llama_new_context_with_model(model, params);
  }

  late final _llama_new_context_with_modelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_context> Function(
            ffi.Pointer<llama_model>,
            llama_context_params,
          )
        >
      >('llama_new_context_with_model');
  late final _llama_new_context_with_model = _llama_new_context_with_modelPtr
      .asFunction<
        ffi.Pointer<llama_context> Function(
          ffi.Pointer<llama_model>,
          llama_context_params,
        )
      >();

  void llama_free(ffi.Pointer<llama_context> ctx) {
    return _llama_free(ctx);
  }

  late final _llama_freePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_free');
  late final _llama_free = _llama_freePtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  int llama_time_us() {
    return _llama_time_us();
  }

  late final _llama_time_usPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('llama_time_us');
  late final _llama_time_us = _llama_time_usPtr.asFunction<int Function()>();

  int llama_max_devices() {
    return _llama_max_devices();
  }

  late final _llama_max_devicesPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('llama_max_devices');
  late final _llama_max_devices = _llama_max_devicesPtr
      .asFunction<int Function()>();

  int llama_max_parallel_sequences() {
    return _llama_max_parallel_sequences();
  }

  late final _llama_max_parallel_sequencesPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>(
        'llama_max_parallel_sequences',
      );
  late final _llama_max_parallel_sequences = _llama_max_parallel_sequencesPtr
      .asFunction<int Function()>();

  bool llama_supports_mmap() {
    return _llama_supports_mmap();
  }

  late final _llama_supports_mmapPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_supports_mmap');
  late final _llama_supports_mmap = _llama_supports_mmapPtr
      .asFunction<bool Function()>();

  bool llama_supports_mlock() {
    return _llama_supports_mlock();
  }

  late final _llama_supports_mlockPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_supports_mlock');
  late final _llama_supports_mlock = _llama_supports_mlockPtr
      .asFunction<bool Function()>();

  bool llama_supports_gpu_offload() {
    return _llama_supports_gpu_offload();
  }

  late final _llama_supports_gpu_offloadPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>(
        'llama_supports_gpu_offload',
      );
  late final _llama_supports_gpu_offload = _llama_supports_gpu_offloadPtr
      .asFunction<bool Function()>();

  bool llama_supports_rpc() {
    return _llama_supports_rpc();
  }

  late final _llama_supports_rpcPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_supports_rpc');
  late final _llama_supports_rpc = _llama_supports_rpcPtr
      .asFunction<bool Function()>();

  int llama_n_ctx(ffi.Pointer<llama_context> ctx) {
    return _llama_n_ctx(ctx);
  }

  late final _llama_n_ctxPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_ctx');
  late final _llama_n_ctx = _llama_n_ctxPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_batch(ffi.Pointer<llama_context> ctx) {
    return _llama_n_batch(ctx);
  }

  late final _llama_n_batchPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_batch');
  late final _llama_n_batch = _llama_n_batchPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_ubatch(ffi.Pointer<llama_context> ctx) {
    return _llama_n_ubatch(ctx);
  }

  late final _llama_n_ubatchPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_ubatch');
  late final _llama_n_ubatch = _llama_n_ubatchPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_seq_max(ffi.Pointer<llama_context> ctx) {
    return _llama_n_seq_max(ctx);
  }

  late final _llama_n_seq_maxPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_seq_max');
  late final _llama_n_seq_max = _llama_n_seq_maxPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_ctx_train(ffi.Pointer<llama_model> model) {
    return _llama_n_ctx_train(model);
  }

  late final _llama_n_ctx_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_n_ctx_train',
      );
  late final _llama_n_ctx_train = _llama_n_ctx_trainPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_embd(ffi.Pointer<llama_model> model) {
    return _llama_n_embd(model);
  }

  late final _llama_n_embdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_n_embd',
      );
  late final _llama_n_embd = _llama_n_embdPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_layer(ffi.Pointer<llama_model> model) {
    return _llama_n_layer(model);
  }

  late final _llama_n_layerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_n_layer',
      );
  late final _llama_n_layer = _llama_n_layerPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_head(ffi.Pointer<llama_model> model) {
    return _llama_n_head(model);
  }

  late final _llama_n_headPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_n_head',
      );
  late final _llama_n_head = _llama_n_headPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_vocab(ffi.Pointer<llama_vocab> vocab) {
    return _llama_n_vocab(vocab);
  }

  late final _llama_n_vocabPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_vocab>)>>(
        'llama_n_vocab',
      );
  late final _llama_n_vocab = _llama_n_vocabPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  ffi.Pointer<llama_model> llama_get_model(ffi.Pointer<llama_context> ctx) {
    return _llama_get_model(ctx);
  }

  late final _llama_get_modelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(ffi.Pointer<llama_context>)
        >
      >('llama_get_model');
  late final _llama_get_model = _llama_get_modelPtr
      .asFunction<
        ffi.Pointer<llama_model> Function(ffi.Pointer<llama_context>)
      >();

  llama_memory_t llama_get_memory(ffi.Pointer<llama_context> ctx) {
    return _llama_get_memory(ctx);
  }

  late final _llama_get_memoryPtr =
      _lookup<
        ffi.NativeFunction<llama_memory_t Function(ffi.Pointer<llama_context>)>
      >('llama_get_memory');
  late final _llama_get_memory = _llama_get_memoryPtr
      .asFunction<llama_memory_t Function(ffi.Pointer<llama_context>)>();

  llama_pooling_type llama_pooling_type$1(ffi.Pointer<llama_context> ctx) {
    return llama_pooling_type.fromValue(_llama_pooling_type$1(ctx));
  }

  late final _llama_pooling_type$1Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
        'llama_pooling_type',
      );
  late final _llama_pooling_type$1 = _llama_pooling_type$1Ptr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<llama_vocab> llama_model_get_vocab(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_get_vocab(model);
  }

  late final _llama_model_get_vocabPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_vocab> Function(ffi.Pointer<llama_model>)
        >
      >('llama_model_get_vocab');
  late final _llama_model_get_vocab = _llama_model_get_vocabPtr
      .asFunction<
        ffi.Pointer<llama_vocab> Function(ffi.Pointer<llama_model>)
      >();

  llama_rope_type llama_model_rope_type(ffi.Pointer<llama_model> model) {
    return llama_rope_type.fromValue(_llama_model_rope_type(model));
  }

  late final _llama_model_rope_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
        'llama_model_rope_type',
      );
  late final _llama_model_rope_type = _llama_model_rope_typePtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_ctx_train(ffi.Pointer<llama_model> model) {
    return _llama_model_n_ctx_train(model);
  }

  late final _llama_model_n_ctx_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_ctx_train',
      );
  late final _llama_model_n_ctx_train = _llama_model_n_ctx_trainPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_embd(ffi.Pointer<llama_model> model) {
    return _llama_model_n_embd(model);
  }

  late final _llama_model_n_embdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_embd',
      );
  late final _llama_model_n_embd = _llama_model_n_embdPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_layer(ffi.Pointer<llama_model> model) {
    return _llama_model_n_layer(model);
  }

  late final _llama_model_n_layerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_layer',
      );
  late final _llama_model_n_layer = _llama_model_n_layerPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_head(ffi.Pointer<llama_model> model) {
    return _llama_model_n_head(model);
  }

  late final _llama_model_n_headPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_head',
      );
  late final _llama_model_n_head = _llama_model_n_headPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_head_kv(ffi.Pointer<llama_model> model) {
    return _llama_model_n_head_kv(model);
  }

  late final _llama_model_n_head_kvPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_head_kv',
      );
  late final _llama_model_n_head_kv = _llama_model_n_head_kvPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_swa(ffi.Pointer<llama_model> model) {
    return _llama_model_n_swa(model);
  }

  late final _llama_model_n_swaPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_n_swa',
      );
  late final _llama_model_n_swa = _llama_model_n_swaPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  double llama_model_rope_freq_scale_train(ffi.Pointer<llama_model> model) {
    return _llama_model_rope_freq_scale_train(model);
  }

  late final _llama_model_rope_freq_scale_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<llama_model>)>>(
        'llama_model_rope_freq_scale_train',
      );
  late final _llama_model_rope_freq_scale_train =
      _llama_model_rope_freq_scale_trainPtr
          .asFunction<double Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_cls_out(ffi.Pointer<llama_model> model) {
    return _llama_model_n_cls_out(model);
  }

  late final _llama_model_n_cls_outPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_model>)>
      >('llama_model_n_cls_out');
  late final _llama_model_n_cls_out = _llama_model_n_cls_outPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<ffi.Char> llama_model_cls_label(
    ffi.Pointer<llama_model> model,
    int i,
  ) {
    return _llama_model_cls_label(model, i);
  }

  late final _llama_model_cls_labelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_model>, ffi.Uint32)
        >
      >('llama_model_cls_label');
  late final _llama_model_cls_label = _llama_model_cls_labelPtr
      .asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_model>, int)
      >();

  llama_vocab_type llama_vocab_type$1(ffi.Pointer<llama_vocab> vocab) {
    return llama_vocab_type.fromValue(_llama_vocab_type$1(vocab));
  }

  late final _llama_vocab_type$1Ptr =
      _lookup<
        ffi.NativeFunction<ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_type');
  late final _llama_vocab_type$1 = _llama_vocab_type$1Ptr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_n_tokens(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_n_tokens(vocab);
  }

  late final _llama_vocab_n_tokensPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_vocab>)>>(
        'llama_vocab_n_tokens',
      );
  late final _llama_vocab_n_tokens = _llama_vocab_n_tokensPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_model_meta_val_str(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> key,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_meta_val_str(model, key, buf, buf_size);
  }

  late final _llama_model_meta_val_strPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_model>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_model_meta_val_str');
  late final _llama_model_meta_val_str = _llama_model_meta_val_strPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_model>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>,
          int,
        )
      >();

  int llama_model_meta_count(ffi.Pointer<llama_model> model) {
    return _llama_model_meta_count(model);
  }

  late final _llama_model_meta_countPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
        'llama_model_meta_count',
      );
  late final _llama_model_meta_count = _llama_model_meta_countPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_meta_key_by_index(
    ffi.Pointer<llama_model> model,
    int i,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_meta_key_by_index(model, i, buf, buf_size);
  }

  late final _llama_model_meta_key_by_indexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_model>,
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_model_meta_key_by_index');
  late final _llama_model_meta_key_by_index = _llama_model_meta_key_by_indexPtr
      .asFunction<
        int Function(ffi.Pointer<llama_model>, int, ffi.Pointer<ffi.Char>, int)
      >();

  int llama_model_meta_val_str_by_index(
    ffi.Pointer<llama_model> model,
    int i,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_meta_val_str_by_index(model, i, buf, buf_size);
  }

  late final _llama_model_meta_val_str_by_indexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_model>,
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_model_meta_val_str_by_index');
  late final _llama_model_meta_val_str_by_index =
      _llama_model_meta_val_str_by_indexPtr
          .asFunction<
            int Function(
              ffi.Pointer<llama_model>,
              int,
              ffi.Pointer<ffi.Char>,
              int,
            )
          >();

  int llama_model_desc(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_desc(model, buf, buf_size);
  }

  late final _llama_model_descPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_model>,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_model_desc');
  late final _llama_model_desc = _llama_model_descPtr
      .asFunction<
        int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, int)
      >();

  int llama_model_size(ffi.Pointer<llama_model> model) {
    return _llama_model_size(model);
  }

  late final _llama_model_sizePtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>
      >('llama_model_size');
  late final _llama_model_size = _llama_model_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<ffi.Char> llama_model_chat_template(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _llama_model_chat_template(model, name);
  }

  late final _llama_model_chat_templatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
            ffi.Pointer<llama_model>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('llama_model_chat_template');
  late final _llama_model_chat_template = _llama_model_chat_templatePtr
      .asFunction<
        ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<llama_model>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  int llama_model_n_params(ffi.Pointer<llama_model> model) {
    return _llama_model_n_params(model);
  }

  late final _llama_model_n_paramsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>
      >('llama_model_n_params');
  late final _llama_model_n_params = _llama_model_n_paramsPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  bool llama_model_has_encoder(ffi.Pointer<llama_model> model) {
    return _llama_model_has_encoder(model);
  }

  late final _llama_model_has_encoderPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_model>)>>(
        'llama_model_has_encoder',
      );
  late final _llama_model_has_encoder = _llama_model_has_encoderPtr
      .asFunction<bool Function(ffi.Pointer<llama_model>)>();

  bool llama_model_has_decoder(ffi.Pointer<llama_model> model) {
    return _llama_model_has_decoder(model);
  }

  late final _llama_model_has_decoderPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_model>)>>(
        'llama_model_has_decoder',
      );
  late final _llama_model_has_decoder = _llama_model_has_decoderPtr
      .asFunction<bool Function(ffi.Pointer<llama_model>)>();

  int llama_model_decoder_start_token(ffi.Pointer<llama_model> model) {
    return _llama_model_decoder_start_token(model);
  }

  late final _llama_model_decoder_start_tokenPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_model>)>
      >('llama_model_decoder_start_token');
  late final _llama_model_decoder_start_token =
      _llama_model_decoder_start_tokenPtr
          .asFunction<int Function(ffi.Pointer<llama_model>)>();

  bool llama_model_is_recurrent(ffi.Pointer<llama_model> model) {
    return _llama_model_is_recurrent(model);
  }

  late final _llama_model_is_recurrentPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_model>)>>(
        'llama_model_is_recurrent',
      );
  late final _llama_model_is_recurrent = _llama_model_is_recurrentPtr
      .asFunction<bool Function(ffi.Pointer<llama_model>)>();

  bool llama_model_is_hybrid(ffi.Pointer<llama_model> model) {
    return _llama_model_is_hybrid(model);
  }

  late final _llama_model_is_hybridPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_model>)>>(
        'llama_model_is_hybrid',
      );
  late final _llama_model_is_hybrid = _llama_model_is_hybridPtr
      .asFunction<bool Function(ffi.Pointer<llama_model>)>();

  bool llama_model_is_diffusion(ffi.Pointer<llama_model> model) {
    return _llama_model_is_diffusion(model);
  }

  late final _llama_model_is_diffusionPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_model>)>>(
        'llama_model_is_diffusion',
      );
  late final _llama_model_is_diffusion = _llama_model_is_diffusionPtr
      .asFunction<bool Function(ffi.Pointer<llama_model>)>();

  int llama_model_quantize(
    ffi.Pointer<ffi.Char> fname_inp,
    ffi.Pointer<ffi.Char> fname_out,
    ffi.Pointer<llama_model_quantize_params> params,
  ) {
    return _llama_model_quantize(fname_inp, fname_out, params);
  }

  late final _llama_model_quantizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Uint32 Function(
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_model_quantize_params>,
          )
        >
      >('llama_model_quantize');
  late final _llama_model_quantize = _llama_model_quantizePtr
      .asFunction<
        int Function(
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_model_quantize_params>,
        )
      >();

  ffi.Pointer<llama_adapter_lora> llama_adapter_lora_init(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> path_lora,
  ) {
    return _llama_adapter_lora_init(model, path_lora);
  }

  late final _llama_adapter_lora_initPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_adapter_lora> Function(
            ffi.Pointer<llama_model>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('llama_adapter_lora_init');
  late final _llama_adapter_lora_init = _llama_adapter_lora_initPtr
      .asFunction<
        ffi.Pointer<llama_adapter_lora> Function(
          ffi.Pointer<llama_model>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  int llama_adapter_meta_val_str(
    ffi.Pointer<llama_adapter_lora> adapter,
    ffi.Pointer<ffi.Char> key,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_adapter_meta_val_str(adapter, key, buf, buf_size);
  }

  late final _llama_adapter_meta_val_strPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_adapter_lora>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_adapter_meta_val_str');
  late final _llama_adapter_meta_val_str = _llama_adapter_meta_val_strPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_adapter_lora>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>,
          int,
        )
      >();

  int llama_adapter_meta_count(ffi.Pointer<llama_adapter_lora> adapter) {
    return _llama_adapter_meta_count(adapter);
  }

  late final _llama_adapter_meta_countPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_adapter_lora>)>
      >('llama_adapter_meta_count');
  late final _llama_adapter_meta_count = _llama_adapter_meta_countPtr
      .asFunction<int Function(ffi.Pointer<llama_adapter_lora>)>();

  int llama_adapter_meta_key_by_index(
    ffi.Pointer<llama_adapter_lora> adapter,
    int i,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_adapter_meta_key_by_index(adapter, i, buf, buf_size);
  }

  late final _llama_adapter_meta_key_by_indexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_adapter_lora>,
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_adapter_meta_key_by_index');
  late final _llama_adapter_meta_key_by_index =
      _llama_adapter_meta_key_by_indexPtr
          .asFunction<
            int Function(
              ffi.Pointer<llama_adapter_lora>,
              int,
              ffi.Pointer<ffi.Char>,
              int,
            )
          >();

  int llama_adapter_meta_val_str_by_index(
    ffi.Pointer<llama_adapter_lora> adapter,
    int i,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_adapter_meta_val_str_by_index(adapter, i, buf, buf_size);
  }

  late final _llama_adapter_meta_val_str_by_indexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_adapter_lora>,
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Size,
          )
        >
      >('llama_adapter_meta_val_str_by_index');
  late final _llama_adapter_meta_val_str_by_index =
      _llama_adapter_meta_val_str_by_indexPtr
          .asFunction<
            int Function(
              ffi.Pointer<llama_adapter_lora>,
              int,
              ffi.Pointer<ffi.Char>,
              int,
            )
          >();

  void llama_adapter_lora_free(ffi.Pointer<llama_adapter_lora> adapter) {
    return _llama_adapter_lora_free(adapter);
  }

  late final _llama_adapter_lora_freePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_adapter_lora>)>
      >('llama_adapter_lora_free');
  late final _llama_adapter_lora_free = _llama_adapter_lora_freePtr
      .asFunction<void Function(ffi.Pointer<llama_adapter_lora>)>();

  int llama_adapter_get_alora_n_invocation_tokens(
    ffi.Pointer<llama_adapter_lora> adapter,
  ) {
    return _llama_adapter_get_alora_n_invocation_tokens(adapter);
  }

  late final _llama_adapter_get_alora_n_invocation_tokensPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_adapter_lora>)>
      >('llama_adapter_get_alora_n_invocation_tokens');
  late final _llama_adapter_get_alora_n_invocation_tokens =
      _llama_adapter_get_alora_n_invocation_tokensPtr
          .asFunction<int Function(ffi.Pointer<llama_adapter_lora>)>();

  ffi.Pointer<llama_token> llama_adapter_get_alora_invocation_tokens(
    ffi.Pointer<llama_adapter_lora> adapter,
  ) {
    return _llama_adapter_get_alora_invocation_tokens(adapter);
  }

  late final _llama_adapter_get_alora_invocation_tokensPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_token> Function(ffi.Pointer<llama_adapter_lora>)
        >
      >('llama_adapter_get_alora_invocation_tokens');
  late final _llama_adapter_get_alora_invocation_tokens =
      _llama_adapter_get_alora_invocation_tokensPtr
          .asFunction<
            ffi.Pointer<llama_token> Function(ffi.Pointer<llama_adapter_lora>)
          >();

  int llama_set_adapter_lora(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_adapter_lora> adapter,
    double scale,
  ) {
    return _llama_set_adapter_lora(ctx, adapter, scale);
  }

  late final _llama_set_adapter_loraPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<llama_adapter_lora>,
            ffi.Float,
          )
        >
      >('llama_set_adapter_lora');
  late final _llama_set_adapter_lora = _llama_set_adapter_loraPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<llama_adapter_lora>,
          double,
        )
      >();

  int llama_rm_adapter_lora(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_adapter_lora> adapter,
  ) {
    return _llama_rm_adapter_lora(ctx, adapter);
  }

  late final _llama_rm_adapter_loraPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<llama_adapter_lora>,
          )
        >
      >('llama_rm_adapter_lora');
  late final _llama_rm_adapter_lora = _llama_rm_adapter_loraPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<llama_adapter_lora>,
        )
      >();

  void llama_clear_adapter_lora(ffi.Pointer<llama_context> ctx) {
    return _llama_clear_adapter_lora(ctx);
  }

  late final _llama_clear_adapter_loraPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_clear_adapter_lora');
  late final _llama_clear_adapter_lora = _llama_clear_adapter_loraPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  int llama_apply_adapter_cvec(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Float> data,
    int len,
    int n_embd,
    int il_start,
    int il_end,
  ) {
    return _llama_apply_adapter_cvec(ctx, data, len, n_embd, il_start, il_end);
  }

  late final _llama_apply_adapter_cvecPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Float>,
            ffi.Size,
            ffi.Int32,
            ffi.Int32,
            ffi.Int32,
          )
        >
      >('llama_apply_adapter_cvec');
  late final _llama_apply_adapter_cvec = _llama_apply_adapter_cvecPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Float>,
          int,
          int,
          int,
          int,
        )
      >();

  void llama_memory_clear(llama_memory_t mem, bool data) {
    return _llama_memory_clear(mem, data);
  }

  late final _llama_memory_clearPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(llama_memory_t, ffi.Bool)>>(
        'llama_memory_clear',
      );
  late final _llama_memory_clear = _llama_memory_clearPtr
      .asFunction<void Function(llama_memory_t, bool)>();

  bool llama_memory_seq_rm(llama_memory_t mem, int seq_id, int p0, int p1) {
    return _llama_memory_seq_rm(mem, seq_id, p0, p1);
  }

  late final _llama_memory_seq_rmPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(llama_memory_t, llama_seq_id, llama_pos, llama_pos)
        >
      >('llama_memory_seq_rm');
  late final _llama_memory_seq_rm = _llama_memory_seq_rmPtr
      .asFunction<bool Function(llama_memory_t, int, int, int)>();

  void llama_memory_seq_cp(
    llama_memory_t mem,
    int seq_id_src,
    int seq_id_dst,
    int p0,
    int p1,
  ) {
    return _llama_memory_seq_cp(mem, seq_id_src, seq_id_dst, p0, p1);
  }

  late final _llama_memory_seq_cpPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            llama_memory_t,
            llama_seq_id,
            llama_seq_id,
            llama_pos,
            llama_pos,
          )
        >
      >('llama_memory_seq_cp');
  late final _llama_memory_seq_cp = _llama_memory_seq_cpPtr
      .asFunction<void Function(llama_memory_t, int, int, int, int)>();

  void llama_memory_seq_keep(llama_memory_t mem, int seq_id) {
    return _llama_memory_seq_keep(mem, seq_id);
  }

  late final _llama_memory_seq_keepPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(llama_memory_t, llama_seq_id)>
      >('llama_memory_seq_keep');
  late final _llama_memory_seq_keep = _llama_memory_seq_keepPtr
      .asFunction<void Function(llama_memory_t, int)>();

  void llama_memory_seq_add(
    llama_memory_t mem,
    int seq_id,
    int p0,
    int p1,
    int delta,
  ) {
    return _llama_memory_seq_add(mem, seq_id, p0, p1, delta);
  }

  late final _llama_memory_seq_addPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            llama_memory_t,
            llama_seq_id,
            llama_pos,
            llama_pos,
            llama_pos,
          )
        >
      >('llama_memory_seq_add');
  late final _llama_memory_seq_add = _llama_memory_seq_addPtr
      .asFunction<void Function(llama_memory_t, int, int, int, int)>();

  void llama_memory_seq_div(
    llama_memory_t mem,
    int seq_id,
    int p0,
    int p1,
    int d,
  ) {
    return _llama_memory_seq_div(mem, seq_id, p0, p1, d);
  }

  late final _llama_memory_seq_divPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            llama_memory_t,
            llama_seq_id,
            llama_pos,
            llama_pos,
            ffi.Int,
          )
        >
      >('llama_memory_seq_div');
  late final _llama_memory_seq_div = _llama_memory_seq_divPtr
      .asFunction<void Function(llama_memory_t, int, int, int, int)>();

  int llama_memory_seq_pos_min(llama_memory_t mem, int seq_id) {
    return _llama_memory_seq_pos_min(mem, seq_id);
  }

  late final _llama_memory_seq_pos_minPtr =
      _lookup<
        ffi.NativeFunction<llama_pos Function(llama_memory_t, llama_seq_id)>
      >('llama_memory_seq_pos_min');
  late final _llama_memory_seq_pos_min = _llama_memory_seq_pos_minPtr
      .asFunction<int Function(llama_memory_t, int)>();

  int llama_memory_seq_pos_max(llama_memory_t mem, int seq_id) {
    return _llama_memory_seq_pos_max(mem, seq_id);
  }

  late final _llama_memory_seq_pos_maxPtr =
      _lookup<
        ffi.NativeFunction<llama_pos Function(llama_memory_t, llama_seq_id)>
      >('llama_memory_seq_pos_max');
  late final _llama_memory_seq_pos_max = _llama_memory_seq_pos_maxPtr
      .asFunction<int Function(llama_memory_t, int)>();

  bool llama_memory_can_shift(llama_memory_t mem) {
    return _llama_memory_can_shift(mem);
  }

  late final _llama_memory_can_shiftPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(llama_memory_t)>>(
        'llama_memory_can_shift',
      );
  late final _llama_memory_can_shift = _llama_memory_can_shiftPtr
      .asFunction<bool Function(llama_memory_t)>();

  int llama_state_get_size(ffi.Pointer<llama_context> ctx) {
    return _llama_state_get_size(ctx);
  }

  late final _llama_state_get_sizePtr =
      _lookup<
        ffi.NativeFunction<ffi.Size Function(ffi.Pointer<llama_context>)>
      >('llama_state_get_size');
  late final _llama_state_get_size = _llama_state_get_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_get_state_size(ffi.Pointer<llama_context> ctx) {
    return _llama_get_state_size(ctx);
  }

  late final _llama_get_state_sizePtr =
      _lookup<
        ffi.NativeFunction<ffi.Size Function(ffi.Pointer<llama_context>)>
      >('llama_get_state_size');
  late final _llama_get_state_size = _llama_get_state_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_state_get_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
    int size,
  ) {
    return _llama_state_get_data(ctx, dst, size);
  }

  late final _llama_state_get_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
          )
        >
      >('llama_state_get_data');
  late final _llama_state_get_data = _llama_state_get_dataPtr
      .asFunction<
        int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>, int)
      >();

  int llama_copy_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
  ) {
    return _llama_copy_state_data(ctx, dst);
  }

  late final _llama_copy_state_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
        >
      >('llama_copy_state_data');
  late final _llama_copy_state_data = _llama_copy_state_dataPtr
      .asFunction<
        int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
      >();

  int llama_state_set_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
    int size,
  ) {
    return _llama_state_set_data(ctx, src, size);
  }

  late final _llama_state_set_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
          )
        >
      >('llama_state_set_data');
  late final _llama_state_set_data = _llama_state_set_dataPtr
      .asFunction<
        int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>, int)
      >();

  int llama_set_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
  ) {
    return _llama_set_state_data(ctx, src);
  }

  late final _llama_set_state_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
        >
      >('llama_set_state_data');
  late final _llama_set_state_data = _llama_set_state_dataPtr
      .asFunction<
        int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
      >();

  bool llama_state_load_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens_out,
    int n_token_capacity,
    ffi.Pointer<ffi.Size> n_token_count_out,
  ) {
    return _llama_state_load_file(
      ctx,
      path_session,
      tokens_out,
      n_token_capacity,
      n_token_count_out,
    );
  }

  late final _llama_state_load_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_token>,
            ffi.Size,
            ffi.Pointer<ffi.Size>,
          )
        >
      >('llama_state_load_file');
  late final _llama_state_load_file = _llama_state_load_filePtr
      .asFunction<
        bool Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>,
          int,
          ffi.Pointer<ffi.Size>,
        )
      >();

  bool llama_load_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens_out,
    int n_token_capacity,
    ffi.Pointer<ffi.Size> n_token_count_out,
  ) {
    return _llama_load_session_file(
      ctx,
      path_session,
      tokens_out,
      n_token_capacity,
      n_token_count_out,
    );
  }

  late final _llama_load_session_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_token>,
            ffi.Size,
            ffi.Pointer<ffi.Size>,
          )
        >
      >('llama_load_session_file');
  late final _llama_load_session_file = _llama_load_session_filePtr
      .asFunction<
        bool Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>,
          int,
          ffi.Pointer<ffi.Size>,
        )
      >();

  bool llama_state_save_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens,
    int n_token_count,
  ) {
    return _llama_state_save_file(ctx, path_session, tokens, n_token_count);
  }

  late final _llama_state_save_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_token>,
            ffi.Size,
          )
        >
      >('llama_state_save_file');
  late final _llama_state_save_file = _llama_state_save_filePtr
      .asFunction<
        bool Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>,
          int,
        )
      >();

  bool llama_save_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens,
    int n_token_count,
  ) {
    return _llama_save_session_file(ctx, path_session, tokens, n_token_count);
  }

  late final _llama_save_session_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_token>,
            ffi.Size,
          )
        >
      >('llama_save_session_file');
  late final _llama_save_session_file = _llama_save_session_filePtr
      .asFunction<
        bool Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>,
          int,
        )
      >();

  int llama_state_seq_get_size(ffi.Pointer<llama_context> ctx, int seq_id) {
    return _llama_state_seq_get_size(ctx, seq_id);
  }

  late final _llama_state_seq_get_sizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>, llama_seq_id)
        >
      >('llama_state_seq_get_size');
  late final _llama_state_seq_get_size = _llama_state_seq_get_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, int)>();

  int llama_state_seq_get_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
    int size,
    int seq_id,
  ) {
    return _llama_state_seq_get_data(ctx, dst, size, seq_id);
  }

  late final _llama_state_seq_get_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
            llama_seq_id,
          )
        >
      >('llama_state_seq_get_data');
  late final _llama_state_seq_get_data = _llama_state_seq_get_dataPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Uint8>,
          int,
          int,
        )
      >();

  int llama_state_seq_set_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
    int size,
    int dest_seq_id,
  ) {
    return _llama_state_seq_set_data(ctx, src, size, dest_seq_id);
  }

  late final _llama_state_seq_set_dataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
            llama_seq_id,
          )
        >
      >('llama_state_seq_set_data');
  late final _llama_state_seq_set_data = _llama_state_seq_set_dataPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Uint8>,
          int,
          int,
        )
      >();

  int llama_state_seq_save_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> filepath,
    int seq_id,
    ffi.Pointer<llama_token> tokens,
    int n_token_count,
  ) {
    return _llama_state_seq_save_file(
      ctx,
      filepath,
      seq_id,
      tokens,
      n_token_count,
    );
  }

  late final _llama_state_seq_save_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            llama_seq_id,
            ffi.Pointer<llama_token>,
            ffi.Size,
          )
        >
      >('llama_state_seq_save_file');
  late final _llama_state_seq_save_file = _llama_state_seq_save_filePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<llama_token>,
          int,
        )
      >();

  int llama_state_seq_load_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> filepath,
    int dest_seq_id,
    ffi.Pointer<llama_token> tokens_out,
    int n_token_capacity,
    ffi.Pointer<ffi.Size> n_token_count_out,
  ) {
    return _llama_state_seq_load_file(
      ctx,
      filepath,
      dest_seq_id,
      tokens_out,
      n_token_capacity,
      n_token_count_out,
    );
  }

  late final _llama_state_seq_load_filePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Char>,
            llama_seq_id,
            ffi.Pointer<llama_token>,
            ffi.Size,
            ffi.Pointer<ffi.Size>,
          )
        >
      >('llama_state_seq_load_file');
  late final _llama_state_seq_load_file = _llama_state_seq_load_filePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<llama_token>,
          int,
          ffi.Pointer<ffi.Size>,
        )
      >();

  int llama_state_seq_get_size_ext(
    ffi.Pointer<llama_context> ctx,
    int seq_id,
    int flags,
  ) {
    return _llama_state_seq_get_size_ext(ctx, seq_id, flags);
  }

  late final _llama_state_seq_get_size_extPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            llama_seq_id,
            llama_state_seq_flags,
          )
        >
      >('llama_state_seq_get_size_ext');
  late final _llama_state_seq_get_size_ext = _llama_state_seq_get_size_extPtr
      .asFunction<int Function(ffi.Pointer<llama_context>, int, int)>();

  int llama_state_seq_get_data_ext(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
    int size,
    int seq_id,
    int flags,
  ) {
    return _llama_state_seq_get_data_ext(ctx, dst, size, seq_id, flags);
  }

  late final _llama_state_seq_get_data_extPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
            llama_seq_id,
            llama_state_seq_flags,
          )
        >
      >('llama_state_seq_get_data_ext');
  late final _llama_state_seq_get_data_ext = _llama_state_seq_get_data_extPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Uint8>,
          int,
          int,
          int,
        )
      >();

  int llama_state_seq_set_data_ext(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
    int size,
    int dest_seq_id,
    int flags,
  ) {
    return _llama_state_seq_set_data_ext(ctx, src, size, dest_seq_id, flags);
  }

  late final _llama_state_seq_set_data_extPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<ffi.Uint8>,
            ffi.Size,
            llama_seq_id,
            llama_state_seq_flags,
          )
        >
      >('llama_state_seq_set_data_ext');
  late final _llama_state_seq_set_data_ext = _llama_state_seq_set_data_extPtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<ffi.Uint8>,
          int,
          int,
          int,
        )
      >();

  llama_batch llama_batch_get_one(
    ffi.Pointer<llama_token> tokens,
    int n_tokens,
  ) {
    return _llama_batch_get_one(tokens, n_tokens);
  }

  late final _llama_batch_get_onePtr =
      _lookup<
        ffi.NativeFunction<
          llama_batch Function(ffi.Pointer<llama_token>, ffi.Int32)
        >
      >('llama_batch_get_one');
  late final _llama_batch_get_one = _llama_batch_get_onePtr
      .asFunction<llama_batch Function(ffi.Pointer<llama_token>, int)>();

  llama_batch llama_batch_init(int n_tokens, int embd, int n_seq_max) {
    return _llama_batch_init(n_tokens, embd, n_seq_max);
  }

  late final _llama_batch_initPtr =
      _lookup<
        ffi.NativeFunction<
          llama_batch Function(ffi.Int32, ffi.Int32, ffi.Int32)
        >
      >('llama_batch_init');
  late final _llama_batch_init = _llama_batch_initPtr
      .asFunction<llama_batch Function(int, int, int)>();

  void llama_batch_free(llama_batch batch) {
    return _llama_batch_free(batch);
  }

  late final _llama_batch_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(llama_batch)>>(
        'llama_batch_free',
      );
  late final _llama_batch_free = _llama_batch_freePtr
      .asFunction<void Function(llama_batch)>();

  int llama_encode(ffi.Pointer<llama_context> ctx, llama_batch batch) {
    return _llama_encode(ctx, batch);
  }

  late final _llama_encodePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<llama_context>, llama_batch)
        >
      >('llama_encode');
  late final _llama_encode = _llama_encodePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, llama_batch)>();

  int llama_decode(ffi.Pointer<llama_context> ctx, llama_batch batch) {
    return _llama_decode(ctx, batch);
  }

  late final _llama_decodePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<llama_context>, llama_batch)
        >
      >('llama_decode');
  late final _llama_decode = _llama_decodePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, llama_batch)>();

  void llama_set_n_threads(
    ffi.Pointer<llama_context> ctx,
    int n_threads,
    int n_threads_batch,
  ) {
    return _llama_set_n_threads(ctx, n_threads, n_threads_batch);
  }

  late final _llama_set_n_threadsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32, ffi.Int32)
        >
      >('llama_set_n_threads');
  late final _llama_set_n_threads = _llama_set_n_threadsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int, int)>();

  int llama_n_threads(ffi.Pointer<llama_context> ctx) {
    return _llama_n_threads(ctx);
  }

  late final _llama_n_threadsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_threads');
  late final _llama_n_threads = _llama_n_threadsPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_threads_batch(ffi.Pointer<llama_context> ctx) {
    return _llama_n_threads_batch(ctx);
  }

  late final _llama_n_threads_batchPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>
      >('llama_n_threads_batch');
  late final _llama_n_threads_batch = _llama_n_threads_batchPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  void llama_set_embeddings(ffi.Pointer<llama_context> ctx, bool embeddings) {
    return _llama_set_embeddings(ctx, embeddings);
  }

  late final _llama_set_embeddingsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)
        >
      >('llama_set_embeddings');
  late final _llama_set_embeddings = _llama_set_embeddingsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, bool)>();

  void llama_set_causal_attn(ffi.Pointer<llama_context> ctx, bool causal_attn) {
    return _llama_set_causal_attn(ctx, causal_attn);
  }

  late final _llama_set_causal_attnPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)
        >
      >('llama_set_causal_attn');
  late final _llama_set_causal_attn = _llama_set_causal_attnPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, bool)>();

  void llama_set_warmup(ffi.Pointer<llama_context> ctx, bool warmup) {
    return _llama_set_warmup(ctx, warmup);
  }

  late final _llama_set_warmupPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)
        >
      >('llama_set_warmup');
  late final _llama_set_warmup = _llama_set_warmupPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, bool)>();

  void llama_set_abort_callback(
    ffi.Pointer<llama_context> ctx,
    ggml_abort_callback abort_callback,
    ffi.Pointer<ffi.Void> abort_callback_data,
  ) {
    return _llama_set_abort_callback(ctx, abort_callback, abort_callback_data);
  }

  late final _llama_set_abort_callbackPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_context>,
            ggml_abort_callback,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('llama_set_abort_callback');
  late final _llama_set_abort_callback = _llama_set_abort_callbackPtr
      .asFunction<
        void Function(
          ffi.Pointer<llama_context>,
          ggml_abort_callback,
          ffi.Pointer<ffi.Void>,
        )
      >();

  void llama_synchronize(ffi.Pointer<llama_context> ctx) {
    return _llama_synchronize(ctx);
  }

  late final _llama_synchronizePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_synchronize');
  late final _llama_synchronize = _llama_synchronizePtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<ffi.Float> llama_get_logits(ffi.Pointer<llama_context> ctx) {
    return _llama_get_logits(ctx);
  }

  late final _llama_get_logitsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)
        >
      >('llama_get_logits');
  late final _llama_get_logits = _llama_get_logitsPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)
      >();

  ffi.Pointer<ffi.Float> llama_get_logits_ith(
    ffi.Pointer<llama_context> ctx,
    int i,
  ) {
    return _llama_get_logits_ith(ctx, i);
  }

  late final _llama_get_logits_ithPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
        >
      >('llama_get_logits_ith');
  late final _llama_get_logits_ith = _llama_get_logits_ithPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, int)
      >();

  ffi.Pointer<ffi.Float> llama_get_embeddings(ffi.Pointer<llama_context> ctx) {
    return _llama_get_embeddings(ctx);
  }

  late final _llama_get_embeddingsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)
        >
      >('llama_get_embeddings');
  late final _llama_get_embeddings = _llama_get_embeddingsPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)
      >();

  ffi.Pointer<ffi.Float> llama_get_embeddings_ith(
    ffi.Pointer<llama_context> ctx,
    int i,
  ) {
    return _llama_get_embeddings_ith(ctx, i);
  }

  late final _llama_get_embeddings_ithPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
        >
      >('llama_get_embeddings_ith');
  late final _llama_get_embeddings_ith = _llama_get_embeddings_ithPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, int)
      >();

  ffi.Pointer<ffi.Float> llama_get_embeddings_seq(
    ffi.Pointer<llama_context> ctx,
    int seq_id,
  ) {
    return _llama_get_embeddings_seq(ctx, seq_id);
  }

  late final _llama_get_embeddings_seqPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
            ffi.Pointer<llama_context>,
            llama_seq_id,
          )
        >
      >('llama_get_embeddings_seq');
  late final _llama_get_embeddings_seq = _llama_get_embeddings_seqPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, int)
      >();

  ffi.Pointer<ffi.Char> llama_vocab_get_text(
    ffi.Pointer<llama_vocab> vocab,
    int token,
  ) {
    return _llama_vocab_get_text(vocab, token);
  }

  late final _llama_vocab_get_textPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_vocab_get_text');
  late final _llama_vocab_get_text = _llama_vocab_get_textPtr
      .asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, int)
      >();

  double llama_vocab_get_score(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_vocab_get_score(vocab, token);
  }

  late final _llama_vocab_get_scorePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_vocab_get_score');
  late final _llama_vocab_get_score = _llama_vocab_get_scorePtr
      .asFunction<double Function(ffi.Pointer<llama_vocab>, int)>();

  llama_token_attr llama_vocab_get_attr(
    ffi.Pointer<llama_vocab> vocab,
    Dartllama_token token,
  ) {
    return llama_token_attr.fromValue(_llama_vocab_get_attr(vocab, token));
  }

  late final _llama_vocab_get_attrPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_vocab_get_attr');
  late final _llama_vocab_get_attr = _llama_vocab_get_attrPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>, int)>();

  bool llama_vocab_is_eog(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_vocab_is_eog(vocab, token);
  }

  late final _llama_vocab_is_eogPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_vocab_is_eog');
  late final _llama_vocab_is_eog = _llama_vocab_is_eogPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>, int)>();

  bool llama_vocab_is_control(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_vocab_is_control(vocab, token);
  }

  late final _llama_vocab_is_controlPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_vocab_is_control');
  late final _llama_vocab_is_control = _llama_vocab_is_controlPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>, int)>();

  int llama_vocab_bos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_bos(vocab);
  }

  late final _llama_vocab_bosPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_bos');
  late final _llama_vocab_bos = _llama_vocab_bosPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_eos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_eos(vocab);
  }

  late final _llama_vocab_eosPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_eos');
  late final _llama_vocab_eos = _llama_vocab_eosPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_eot(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_eot(vocab);
  }

  late final _llama_vocab_eotPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_eot');
  late final _llama_vocab_eot = _llama_vocab_eotPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_sep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_sep(vocab);
  }

  late final _llama_vocab_sepPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_sep');
  late final _llama_vocab_sep = _llama_vocab_sepPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_nl(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_nl(vocab);
  }

  late final _llama_vocab_nlPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_nl');
  late final _llama_vocab_nl = _llama_vocab_nlPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_pad(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_pad(vocab);
  }

  late final _llama_vocab_padPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_pad');
  late final _llama_vocab_pad = _llama_vocab_padPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_mask(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_mask(vocab);
  }

  late final _llama_vocab_maskPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_mask');
  late final _llama_vocab_mask = _llama_vocab_maskPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  bool llama_vocab_get_add_bos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_get_add_bos(vocab);
  }

  late final _llama_vocab_get_add_bosPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_vocab>)>>(
        'llama_vocab_get_add_bos',
      );
  late final _llama_vocab_get_add_bos = _llama_vocab_get_add_bosPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>)>();

  bool llama_vocab_get_add_eos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_get_add_eos(vocab);
  }

  late final _llama_vocab_get_add_eosPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_vocab>)>>(
        'llama_vocab_get_add_eos',
      );
  late final _llama_vocab_get_add_eos = _llama_vocab_get_add_eosPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>)>();

  bool llama_vocab_get_add_sep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_get_add_sep(vocab);
  }

  late final _llama_vocab_get_add_sepPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_vocab>)>>(
        'llama_vocab_get_add_sep',
      );
  late final _llama_vocab_get_add_sep = _llama_vocab_get_add_sepPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_pre(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_pre(vocab);
  }

  late final _llama_vocab_fim_prePtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_pre');
  late final _llama_vocab_fim_pre = _llama_vocab_fim_prePtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_suf(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_suf(vocab);
  }

  late final _llama_vocab_fim_sufPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_suf');
  late final _llama_vocab_fim_suf = _llama_vocab_fim_sufPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_mid(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_mid(vocab);
  }

  late final _llama_vocab_fim_midPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_mid');
  late final _llama_vocab_fim_mid = _llama_vocab_fim_midPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_pad(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_pad(vocab);
  }

  late final _llama_vocab_fim_padPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_pad');
  late final _llama_vocab_fim_pad = _llama_vocab_fim_padPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_rep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_rep(vocab);
  }

  late final _llama_vocab_fim_repPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_rep');
  late final _llama_vocab_fim_rep = _llama_vocab_fim_repPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_fim_sep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_fim_sep(vocab);
  }

  late final _llama_vocab_fim_sepPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_fim_sep');
  late final _llama_vocab_fim_sep = _llama_vocab_fim_sepPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  ffi.Pointer<ffi.Char> llama_token_get_text(
    ffi.Pointer<llama_vocab> vocab,
    int token,
  ) {
    return _llama_token_get_text(vocab, token);
  }

  late final _llama_token_get_textPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_token_get_text');
  late final _llama_token_get_text = _llama_token_get_textPtr
      .asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, int)
      >();

  double llama_token_get_score(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_token_get_score(vocab, token);
  }

  late final _llama_token_get_scorePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_token_get_score');
  late final _llama_token_get_score = _llama_token_get_scorePtr
      .asFunction<double Function(ffi.Pointer<llama_vocab>, int)>();

  llama_token_attr llama_token_get_attr(
    ffi.Pointer<llama_vocab> vocab,
    Dartllama_token token,
  ) {
    return llama_token_attr.fromValue(_llama_token_get_attr(vocab, token));
  }

  late final _llama_token_get_attrPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_token_get_attr');
  late final _llama_token_get_attr = _llama_token_get_attrPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>, int)>();

  bool llama_token_is_eog(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_token_is_eog(vocab, token);
  }

  late final _llama_token_is_eogPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_token_is_eog');
  late final _llama_token_is_eog = _llama_token_is_eogPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>, int)>();

  bool llama_token_is_control(ffi.Pointer<llama_vocab> vocab, int token) {
    return _llama_token_is_control(vocab, token);
  }

  late final _llama_token_is_controlPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)
        >
      >('llama_token_is_control');
  late final _llama_token_is_control = _llama_token_is_controlPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>, int)>();

  int llama_token_bos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_bos(vocab);
  }

  late final _llama_token_bosPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_bos');
  late final _llama_token_bos = _llama_token_bosPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_eos(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_eos(vocab);
  }

  late final _llama_token_eosPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_eos');
  late final _llama_token_eos = _llama_token_eosPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_eot(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_eot(vocab);
  }

  late final _llama_token_eotPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_eot');
  late final _llama_token_eot = _llama_token_eotPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_cls(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_cls(vocab);
  }

  late final _llama_token_clsPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_cls');
  late final _llama_token_cls = _llama_token_clsPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_sep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_sep(vocab);
  }

  late final _llama_token_sepPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_sep');
  late final _llama_token_sep = _llama_token_sepPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_nl(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_nl(vocab);
  }

  late final _llama_token_nlPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_nl');
  late final _llama_token_nl = _llama_token_nlPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_pad(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_pad(vocab);
  }

  late final _llama_token_padPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_pad');
  late final _llama_token_pad = _llama_token_padPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  bool llama_add_bos_token(ffi.Pointer<llama_vocab> vocab) {
    return _llama_add_bos_token(vocab);
  }

  late final _llama_add_bos_tokenPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_vocab>)>>(
        'llama_add_bos_token',
      );
  late final _llama_add_bos_token = _llama_add_bos_tokenPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>)>();

  bool llama_add_eos_token(ffi.Pointer<llama_vocab> vocab) {
    return _llama_add_eos_token(vocab);
  }

  late final _llama_add_eos_tokenPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<llama_vocab>)>>(
        'llama_add_eos_token',
      );
  late final _llama_add_eos_token = _llama_add_eos_tokenPtr
      .asFunction<bool Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_pre(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_pre(vocab);
  }

  late final _llama_token_fim_prePtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_pre');
  late final _llama_token_fim_pre = _llama_token_fim_prePtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_suf(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_suf(vocab);
  }

  late final _llama_token_fim_sufPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_suf');
  late final _llama_token_fim_suf = _llama_token_fim_sufPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_mid(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_mid(vocab);
  }

  late final _llama_token_fim_midPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_mid');
  late final _llama_token_fim_mid = _llama_token_fim_midPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_pad(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_pad(vocab);
  }

  late final _llama_token_fim_padPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_pad');
  late final _llama_token_fim_pad = _llama_token_fim_padPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_rep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_rep(vocab);
  }

  late final _llama_token_fim_repPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_rep');
  late final _llama_token_fim_rep = _llama_token_fim_repPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_token_fim_sep(ffi.Pointer<llama_vocab> vocab) {
    return _llama_token_fim_sep(vocab);
  }

  late final _llama_token_fim_sepPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_token_fim_sep');
  late final _llama_token_fim_sep = _llama_token_fim_sepPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  int llama_vocab_cls(ffi.Pointer<llama_vocab> vocab) {
    return _llama_vocab_cls(vocab);
  }

  late final _llama_vocab_clsPtr =
      _lookup<
        ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_vocab>)>
      >('llama_vocab_cls');
  late final _llama_vocab_cls = _llama_vocab_clsPtr
      .asFunction<int Function(ffi.Pointer<llama_vocab>)>();

  /// @details Convert the provided text into tokens.
  /// @param tokens The tokens pointer must be large enough to hold the resulting tokens.
  /// @return Returns the number of tokens on success, no more than n_tokens_max
  /// @return Returns a negative number on failure - the number of tokens that would have been returned
  /// @return Returns INT32_MIN on overflow (e.g., tokenization result size exceeds int32_t limit)
  /// @param add_special Allow to add BOS and EOS tokens if model is configured to do so.
  /// @param parse_special Allow tokenizing special and/or control tokens which otherwise are not exposed and treated
  /// as plaintext. Does not insert a leading space.
  int llama_tokenize(
    ffi.Pointer<llama_vocab> vocab,
    ffi.Pointer<ffi.Char> text,
    int text_len,
    ffi.Pointer<llama_token> tokens,
    int n_tokens_max,
    bool add_special,
    bool parse_special,
  ) {
    return _llama_tokenize(
      vocab,
      text,
      text_len,
      tokens,
      n_tokens_max,
      add_special,
      parse_special,
    );
  }

  late final _llama_tokenizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_vocab>,
            ffi.Pointer<ffi.Char>,
            ffi.Int32,
            ffi.Pointer<llama_token>,
            ffi.Int32,
            ffi.Bool,
            ffi.Bool,
          )
        >
      >('llama_tokenize');
  late final _llama_tokenize = _llama_tokenizePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_vocab>,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<llama_token>,
          int,
          bool,
          bool,
        )
      >();

  int llama_token_to_piece(
    ffi.Pointer<llama_vocab> vocab,
    int token,
    ffi.Pointer<ffi.Char> buf,
    int length,
    int lstrip,
    bool special,
  ) {
    return _llama_token_to_piece(vocab, token, buf, length, lstrip, special);
  }

  late final _llama_token_to_piecePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_vocab>,
            llama_token,
            ffi.Pointer<ffi.Char>,
            ffi.Int32,
            ffi.Int32,
            ffi.Bool,
          )
        >
      >('llama_token_to_piece');
  late final _llama_token_to_piece = _llama_token_to_piecePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_vocab>,
          int,
          ffi.Pointer<ffi.Char>,
          int,
          int,
          bool,
        )
      >();

  /// @details Convert the provided tokens into text (inverse of llama_tokenize()).
  /// @param text The char pointer must be large enough to hold the resulting text.
  /// @return Returns the number of chars/bytes on success, no more than text_len_max.
  /// @return Returns a negative number on failure - the number of chars/bytes that would have been returned.
  /// @param remove_special Allow to remove BOS and EOS tokens if model is configured to do so.
  /// @param unparse_special If true, special tokens are rendered in the output.
  int llama_detokenize(
    ffi.Pointer<llama_vocab> vocab,
    ffi.Pointer<llama_token> tokens,
    int n_tokens,
    ffi.Pointer<ffi.Char> text,
    int text_len_max,
    bool remove_special,
    bool unparse_special,
  ) {
    return _llama_detokenize(
      vocab,
      tokens,
      n_tokens,
      text,
      text_len_max,
      remove_special,
      unparse_special,
    );
  }

  late final _llama_detokenizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<llama_vocab>,
            ffi.Pointer<llama_token>,
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Int32,
            ffi.Bool,
            ffi.Bool,
          )
        >
      >('llama_detokenize');
  late final _llama_detokenize = _llama_detokenizePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_vocab>,
          ffi.Pointer<llama_token>,
          int,
          ffi.Pointer<ffi.Char>,
          int,
          bool,
          bool,
        )
      >();

  /// Apply chat template. Inspired by hf apply_chat_template() on python.
  /// Both "model" and "custom_template" are optional, but at least one is required. "custom_template" has higher precedence than "model"
  /// NOTE: This function does not use a jinja parser. It only support a pre-defined list of template. See more: https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template
  /// @param tmpl A Jinja template to use for this chat. If this is nullptr, the models default chat template will be used instead.
  /// @param chat Pointer to a list of multiple llama_chat_message
  /// @param n_msg Number of llama_chat_message in this chat
  /// @param add_ass Whether to end the prompt with the token(s) that indicate the start of an assistant message.
  /// @param buf A buffer to hold the output formatted prompt. The recommended alloc size is 2 * (total number of characters of all messages)
  /// @param length The size of the allocated buffer
  /// @return The total number of bytes of the formatted prompt. If is it larger than the size of buffer, you may need to re-alloc it and then re-apply the template.
  int llama_chat_apply_template(
    ffi.Pointer<ffi.Char> tmpl,
    ffi.Pointer<llama_chat_message> chat,
    int n_msg,
    bool add_ass,
    ffi.Pointer<ffi.Char> buf,
    int length,
  ) {
    return _llama_chat_apply_template(tmpl, chat, n_msg, add_ass, buf, length);
  }

  late final _llama_chat_apply_templatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<llama_chat_message>,
            ffi.Size,
            ffi.Bool,
            ffi.Pointer<ffi.Char>,
            ffi.Int32,
          )
        >
      >('llama_chat_apply_template');
  late final _llama_chat_apply_template = _llama_chat_apply_templatePtr
      .asFunction<
        int Function(
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_chat_message>,
          int,
          bool,
          ffi.Pointer<ffi.Char>,
          int,
        )
      >();

  int llama_chat_builtin_templates(
    ffi.Pointer<ffi.Pointer<ffi.Char>> output,
    int len,
  ) {
    return _llama_chat_builtin_templates(output, len);
  }

  late final _llama_chat_builtin_templatesPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Size)
        >
      >('llama_chat_builtin_templates');
  late final _llama_chat_builtin_templates = _llama_chat_builtin_templatesPtr
      .asFunction<int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  ffi.Pointer<llama_sampler> llama_sampler_init(
    ffi.Pointer<llama_sampler_i> iface,
    llama_sampler_context_t ctx,
  ) {
    return _llama_sampler_init(iface, ctx);
  }

  late final _llama_sampler_initPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_sampler_i>,
            llama_sampler_context_t,
          )
        >
      >('llama_sampler_init');
  late final _llama_sampler_init = _llama_sampler_initPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(
          ffi.Pointer<llama_sampler_i>,
          llama_sampler_context_t,
        )
      >();

  ffi.Pointer<ffi.Char> llama_sampler_name(ffi.Pointer<llama_sampler> smpl) {
    return _llama_sampler_name(smpl);
  }

  late final _llama_sampler_namePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_sampler>)
        >
      >('llama_sampler_name');
  late final _llama_sampler_name = _llama_sampler_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_sampler>)>();

  void llama_sampler_accept(ffi.Pointer<llama_sampler> smpl, int token) {
    return _llama_sampler_accept(smpl, token);
  }

  late final _llama_sampler_acceptPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_sampler>, llama_token)
        >
      >('llama_sampler_accept');
  late final _llama_sampler_accept = _llama_sampler_acceptPtr
      .asFunction<void Function(ffi.Pointer<llama_sampler>, int)>();

  void llama_sampler_apply(
    ffi.Pointer<llama_sampler> smpl,
    ffi.Pointer<llama_token_data_array> cur_p,
  ) {
    return _llama_sampler_apply(smpl, cur_p);
  }

  late final _llama_sampler_applyPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_sampler>,
            ffi.Pointer<llama_token_data_array>,
          )
        >
      >('llama_sampler_apply');
  late final _llama_sampler_apply = _llama_sampler_applyPtr
      .asFunction<
        void Function(
          ffi.Pointer<llama_sampler>,
          ffi.Pointer<llama_token_data_array>,
        )
      >();

  void llama_sampler_reset(ffi.Pointer<llama_sampler> smpl) {
    return _llama_sampler_reset(smpl);
  }

  late final _llama_sampler_resetPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler>)>
      >('llama_sampler_reset');
  late final _llama_sampler_reset = _llama_sampler_resetPtr
      .asFunction<void Function(ffi.Pointer<llama_sampler>)>();

  ffi.Pointer<llama_sampler> llama_sampler_clone(
    ffi.Pointer<llama_sampler> smpl,
  ) {
    return _llama_sampler_clone(smpl);
  }

  late final _llama_sampler_clonePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>)
        >
      >('llama_sampler_clone');
  late final _llama_sampler_clone = _llama_sampler_clonePtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>)
      >();

  void llama_sampler_free(ffi.Pointer<llama_sampler> smpl) {
    return _llama_sampler_free(smpl);
  }

  late final _llama_sampler_freePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler>)>
      >('llama_sampler_free');
  late final _llama_sampler_free = _llama_sampler_freePtr
      .asFunction<void Function(ffi.Pointer<llama_sampler>)>();

  ffi.Pointer<llama_sampler> llama_sampler_chain_init(
    llama_sampler_chain_params params,
  ) {
    return _llama_sampler_chain_init(params);
  }

  late final _llama_sampler_chain_initPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(llama_sampler_chain_params)
        >
      >('llama_sampler_chain_init');
  late final _llama_sampler_chain_init = _llama_sampler_chain_initPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(llama_sampler_chain_params)
      >();

  void llama_sampler_chain_add(
    ffi.Pointer<llama_sampler> chain,
    ffi.Pointer<llama_sampler> smpl,
  ) {
    return _llama_sampler_chain_add(chain, smpl);
  }

  late final _llama_sampler_chain_addPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_sampler>,
            ffi.Pointer<llama_sampler>,
          )
        >
      >('llama_sampler_chain_add');
  late final _llama_sampler_chain_add = _llama_sampler_chain_addPtr
      .asFunction<
        void Function(ffi.Pointer<llama_sampler>, ffi.Pointer<llama_sampler>)
      >();

  ffi.Pointer<llama_sampler> llama_sampler_chain_get(
    ffi.Pointer<llama_sampler> chain,
    int i,
  ) {
    return _llama_sampler_chain_get(chain, i);
  }

  late final _llama_sampler_chain_getPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_sampler>,
            ffi.Int32,
          )
        >
      >('llama_sampler_chain_get');
  late final _llama_sampler_chain_get = _llama_sampler_chain_getPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>, int)
      >();

  int llama_sampler_chain_n(ffi.Pointer<llama_sampler> chain) {
    return _llama_sampler_chain_n(chain);
  }

  late final _llama_sampler_chain_nPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_sampler>)>>(
        'llama_sampler_chain_n',
      );
  late final _llama_sampler_chain_n = _llama_sampler_chain_nPtr
      .asFunction<int Function(ffi.Pointer<llama_sampler>)>();

  ffi.Pointer<llama_sampler> llama_sampler_chain_remove(
    ffi.Pointer<llama_sampler> chain,
    int i,
  ) {
    return _llama_sampler_chain_remove(chain, i);
  }

  late final _llama_sampler_chain_removePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_sampler>,
            ffi.Int32,
          )
        >
      >('llama_sampler_chain_remove');
  late final _llama_sampler_chain_remove = _llama_sampler_chain_removePtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>, int)
      >();

  ffi.Pointer<llama_sampler> llama_sampler_init_greedy() {
    return _llama_sampler_init_greedy();
  }

  late final _llama_sampler_init_greedyPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<llama_sampler> Function()>>(
        'llama_sampler_init_greedy',
      );
  late final _llama_sampler_init_greedy = _llama_sampler_init_greedyPtr
      .asFunction<ffi.Pointer<llama_sampler> Function()>();

  ffi.Pointer<llama_sampler> llama_sampler_init_dist(int seed) {
    return _llama_sampler_init_dist(seed);
  }

  late final _llama_sampler_init_distPtr =
      _lookup<
        ffi.NativeFunction<ffi.Pointer<llama_sampler> Function(ffi.Uint32)>
      >('llama_sampler_init_dist');
  late final _llama_sampler_init_dist = _llama_sampler_init_distPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(int)>();

  /// @details Top-K sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  /// Setting k <= 0 makes this a noop
  ffi.Pointer<llama_sampler> llama_sampler_init_top_k(int k) {
    return _llama_sampler_init_top_k(k);
  }

  late final _llama_sampler_init_top_kPtr =
      _lookup<
        ffi.NativeFunction<ffi.Pointer<llama_sampler> Function(ffi.Int32)>
      >('llama_sampler_init_top_k');
  late final _llama_sampler_init_top_k = _llama_sampler_init_top_kPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(int)>();

  /// @details Nucleus sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  ffi.Pointer<llama_sampler> llama_sampler_init_top_p(double p, int min_keep) {
    return _llama_sampler_init_top_p(p, min_keep);
  }

  late final _llama_sampler_init_top_pPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)
        >
      >('llama_sampler_init_top_p');
  late final _llama_sampler_init_top_p = _llama_sampler_init_top_pPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(double, int)>();

  /// @details Minimum P sampling as described in https://github.com/ggml-org/llama.cpp/pull/3841
  ffi.Pointer<llama_sampler> llama_sampler_init_min_p(double p, int min_keep) {
    return _llama_sampler_init_min_p(p, min_keep);
  }

  late final _llama_sampler_init_min_pPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)
        >
      >('llama_sampler_init_min_p');
  late final _llama_sampler_init_min_p = _llama_sampler_init_min_pPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(double, int)>();

  /// @details Locally Typical Sampling implementation described in the paper https://arxiv.org/abs/2202.00666.
  ffi.Pointer<llama_sampler> llama_sampler_init_typical(
    double p,
    int min_keep,
  ) {
    return _llama_sampler_init_typical(p, min_keep);
  }

  late final _llama_sampler_init_typicalPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)
        >
      >('llama_sampler_init_typical');
  late final _llama_sampler_init_typical = _llama_sampler_init_typicalPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(double, int)>();

  /// #details Updates the logits l_i` = l_i/t. When t <= 0.0f, the maximum logit is kept at it's original value, the rest are set to -inf
  ffi.Pointer<llama_sampler> llama_sampler_init_temp(double t) {
    return _llama_sampler_init_temp(t);
  }

  late final _llama_sampler_init_tempPtr =
      _lookup<
        ffi.NativeFunction<ffi.Pointer<llama_sampler> Function(ffi.Float)>
      >('llama_sampler_init_temp');
  late final _llama_sampler_init_temp = _llama_sampler_init_tempPtr
      .asFunction<ffi.Pointer<llama_sampler> Function(double)>();

  /// @details Dynamic temperature implementation (a.k.a. entropy) described in the paper https://arxiv.org/abs/2309.02772.
  ffi.Pointer<llama_sampler> llama_sampler_init_temp_ext(
    double t,
    double delta,
    double exponent,
  ) {
    return _llama_sampler_init_temp_ext(t, delta, exponent);
  }

  late final _llama_sampler_init_temp_extPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Float, ffi.Float)
        >
      >('llama_sampler_init_temp_ext');
  late final _llama_sampler_init_temp_ext = _llama_sampler_init_temp_extPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(double, double, double)
      >();

  /// @details XTC sampler as described in https://github.com/oobabooga/text-generation-webui/pull/6335
  ffi.Pointer<llama_sampler> llama_sampler_init_xtc(
    double p,
    double t,
    int min_keep,
    int seed,
  ) {
    return _llama_sampler_init_xtc(p, t, min_keep, seed);
  }

  late final _llama_sampler_init_xtcPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Float,
            ffi.Float,
            ffi.Size,
            ffi.Uint32,
          )
        >
      >('llama_sampler_init_xtc');
  late final _llama_sampler_init_xtc = _llama_sampler_init_xtcPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(double, double, int, int)
      >();

  /// @details Top n sigma sampling as described in academic paper "Top-n: Not All Logits Are You Need" https://arxiv.org/pdf/2411.07641
  ffi.Pointer<llama_sampler> llama_sampler_init_top_n_sigma(double n) {
    return _llama_sampler_init_top_n_sigma(n);
  }

  late final _llama_sampler_init_top_n_sigmaPtr =
      _lookup<
        ffi.NativeFunction<ffi.Pointer<llama_sampler> Function(ffi.Float)>
      >('llama_sampler_init_top_n_sigma');
  late final _llama_sampler_init_top_n_sigma =
      _llama_sampler_init_top_n_sigmaPtr
          .asFunction<ffi.Pointer<llama_sampler> Function(double)>();

  /// @details Mirostat 1.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param m The number of tokens considered in the estimation of `s_hat`. This is an arbitrary value that is used to calculate `s_hat`, which in turn helps to calculate the value of `k`. In the paper, they use `m = 100`, but you can experiment with different values to see how it affects the performance of the algorithm.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  ffi.Pointer<llama_sampler> llama_sampler_init_mirostat(
    int n_vocab,
    int seed,
    double tau,
    double eta,
    int m,
  ) {
    return _llama_sampler_init_mirostat(n_vocab, seed, tau, eta, m);
  }

  late final _llama_sampler_init_mirostatPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Int32,
            ffi.Uint32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
          )
        >
      >('llama_sampler_init_mirostat');
  late final _llama_sampler_init_mirostat = _llama_sampler_init_mirostatPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(int, int, double, double, int)
      >();

  /// @details Mirostat 2.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  ffi.Pointer<llama_sampler> llama_sampler_init_mirostat_v2(
    int seed,
    double tau,
    double eta,
  ) {
    return _llama_sampler_init_mirostat_v2(seed, tau, eta);
  }

  late final _llama_sampler_init_mirostat_v2Ptr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Uint32, ffi.Float, ffi.Float)
        >
      >('llama_sampler_init_mirostat_v2');
  late final _llama_sampler_init_mirostat_v2 =
      _llama_sampler_init_mirostat_v2Ptr
          .asFunction<
            ffi.Pointer<llama_sampler> Function(int, double, double)
          >();

  /// @details Intializes a GBNF grammar, see grammars/README.md for details.
  /// @param vocab The vocabulary that this grammar will be used with.
  /// @param grammar_str The production rules for the grammar, encoded as a string. Returns an empty grammar if empty. Returns NULL if parsing of grammar_str fails.
  /// @param grammar_root The name of the start symbol for the grammar.
  ffi.Pointer<llama_sampler> llama_sampler_init_grammar(
    ffi.Pointer<llama_vocab> vocab,
    ffi.Pointer<ffi.Char> grammar_str,
    ffi.Pointer<ffi.Char> grammar_root,
  ) {
    return _llama_sampler_init_grammar(vocab, grammar_str, grammar_root);
  }

  late final _llama_sampler_init_grammarPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_vocab>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('llama_sampler_init_grammar');
  late final _llama_sampler_init_grammar = _llama_sampler_init_grammarPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(
          ffi.Pointer<llama_vocab>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  ffi.Pointer<llama_sampler> llama_sampler_init_grammar_lazy(
    ffi.Pointer<llama_vocab> vocab,
    ffi.Pointer<ffi.Char> grammar_str,
    ffi.Pointer<ffi.Char> grammar_root,
    ffi.Pointer<ffi.Pointer<ffi.Char>> trigger_words,
    int num_trigger_words,
    ffi.Pointer<llama_token> trigger_tokens,
    int num_trigger_tokens,
  ) {
    return _llama_sampler_init_grammar_lazy(
      vocab,
      grammar_str,
      grammar_root,
      trigger_words,
      num_trigger_words,
      trigger_tokens,
      num_trigger_tokens,
    );
  }

  late final _llama_sampler_init_grammar_lazyPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_vocab>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Size,
            ffi.Pointer<llama_token>,
            ffi.Size,
          )
        >
      >('llama_sampler_init_grammar_lazy');
  late final _llama_sampler_init_grammar_lazy =
      _llama_sampler_init_grammar_lazyPtr
          .asFunction<
            ffi.Pointer<llama_sampler> Function(
              ffi.Pointer<llama_vocab>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              int,
              ffi.Pointer<llama_token>,
              int,
            )
          >();

  /// @details Lazy grammar sampler, introduced in https://github.com/ggml-org/llama.cpp/pull/9639
  /// @param trigger_patterns A list of patterns that will trigger the grammar sampler. Pattern will be matched from the start of the generation output, and grammar sampler will be fed content starting from its first match group.
  /// @param trigger_tokens A list of tokens that will trigger the grammar sampler. Grammar sampler will be fed content starting from the trigger token included.
  ffi.Pointer<llama_sampler> llama_sampler_init_grammar_lazy_patterns(
    ffi.Pointer<llama_vocab> vocab,
    ffi.Pointer<ffi.Char> grammar_str,
    ffi.Pointer<ffi.Char> grammar_root,
    ffi.Pointer<ffi.Pointer<ffi.Char>> trigger_patterns,
    int num_trigger_patterns,
    ffi.Pointer<llama_token> trigger_tokens,
    int num_trigger_tokens,
  ) {
    return _llama_sampler_init_grammar_lazy_patterns(
      vocab,
      grammar_str,
      grammar_root,
      trigger_patterns,
      num_trigger_patterns,
      trigger_tokens,
      num_trigger_tokens,
    );
  }

  late final _llama_sampler_init_grammar_lazy_patternsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_vocab>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Size,
            ffi.Pointer<llama_token>,
            ffi.Size,
          )
        >
      >('llama_sampler_init_grammar_lazy_patterns');
  late final _llama_sampler_init_grammar_lazy_patterns =
      _llama_sampler_init_grammar_lazy_patternsPtr
          .asFunction<
            ffi.Pointer<llama_sampler> Function(
              ffi.Pointer<llama_vocab>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              int,
              ffi.Pointer<llama_token>,
              int,
            )
          >();

  /// NOTE: Avoid using on the full vocabulary as searching for repeated tokens can become slow. For example, apply top-k or top-p sampling first.
  ffi.Pointer<llama_sampler> llama_sampler_init_penalties(
    int penalty_last_n,
    double penalty_repeat,
    double penalty_freq,
    double penalty_present,
  ) {
    return _llama_sampler_init_penalties(
      penalty_last_n,
      penalty_repeat,
      penalty_freq,
      penalty_present,
    );
  }

  late final _llama_sampler_init_penaltiesPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Float,
          )
        >
      >('llama_sampler_init_penalties');
  late final _llama_sampler_init_penalties = _llama_sampler_init_penaltiesPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(int, double, double, double)
      >();

  /// @details DRY sampler, designed by p-e-w, as described in: https://github.com/oobabooga/text-generation-webui/pull/5677, porting Koboldcpp implementation authored by pi6am: https://github.com/LostRuins/koboldcpp/pull/982
  ffi.Pointer<llama_sampler> llama_sampler_init_dry(
    ffi.Pointer<llama_vocab> vocab,
    int n_ctx_train,
    double dry_multiplier,
    double dry_base,
    int dry_allowed_length,
    int dry_penalty_last_n,
    ffi.Pointer<ffi.Pointer<ffi.Char>> seq_breakers,
    int num_breakers,
  ) {
    return _llama_sampler_init_dry(
      vocab,
      n_ctx_train,
      dry_multiplier,
      dry_base,
      dry_allowed_length,
      dry_penalty_last_n,
      seq_breakers,
      num_breakers,
    );
  }

  late final _llama_sampler_init_dryPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Pointer<llama_vocab>,
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
            ffi.Int32,
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Size,
          )
        >
      >('llama_sampler_init_dry');
  late final _llama_sampler_init_dry = _llama_sampler_init_dryPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(
          ffi.Pointer<llama_vocab>,
          int,
          double,
          double,
          int,
          int,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          int,
        )
      >();

  ffi.Pointer<llama_sampler> llama_sampler_init_logit_bias(
    int n_vocab,
    int n_logit_bias,
    ffi.Pointer<llama_logit_bias> logit_bias,
  ) {
    return _llama_sampler_init_logit_bias(n_vocab, n_logit_bias, logit_bias);
  }

  late final _llama_sampler_init_logit_biasPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(
            ffi.Int32,
            ffi.Int32,
            ffi.Pointer<llama_logit_bias>,
          )
        >
      >('llama_sampler_init_logit_bias');
  late final _llama_sampler_init_logit_bias = _llama_sampler_init_logit_biasPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(
          int,
          int,
          ffi.Pointer<llama_logit_bias>,
        )
      >();

  ffi.Pointer<llama_sampler> llama_sampler_init_infill(
    ffi.Pointer<llama_vocab> vocab,
  ) {
    return _llama_sampler_init_infill(vocab);
  }

  late final _llama_sampler_init_infillPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_vocab>)
        >
      >('llama_sampler_init_infill');
  late final _llama_sampler_init_infill = _llama_sampler_init_infillPtr
      .asFunction<
        ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_vocab>)
      >();

  int llama_sampler_get_seed(ffi.Pointer<llama_sampler> smpl) {
    return _llama_sampler_get_seed(smpl);
  }

  late final _llama_sampler_get_seedPtr =
      _lookup<
        ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<llama_sampler>)>
      >('llama_sampler_get_seed');
  late final _llama_sampler_get_seed = _llama_sampler_get_seedPtr
      .asFunction<int Function(ffi.Pointer<llama_sampler>)>();

  int llama_sampler_sample(
    ffi.Pointer<llama_sampler> smpl,
    ffi.Pointer<llama_context> ctx,
    int idx,
  ) {
    return _llama_sampler_sample(smpl, ctx, idx);
  }

  late final _llama_sampler_samplePtr =
      _lookup<
        ffi.NativeFunction<
          llama_token Function(
            ffi.Pointer<llama_sampler>,
            ffi.Pointer<llama_context>,
            ffi.Int32,
          )
        >
      >('llama_sampler_sample');
  late final _llama_sampler_sample = _llama_sampler_samplePtr
      .asFunction<
        int Function(
          ffi.Pointer<llama_sampler>,
          ffi.Pointer<llama_context>,
          int,
        )
      >();

  /// @details Build a split GGUF final path for this chunk.
  /// llama_split_path(split_path, sizeof(split_path), "/models/ggml-model-q4_0", 2, 4) => split_path = "/models/ggml-model-q4_0-00002-of-00004.gguf"
  int llama_split_path(
    ffi.Pointer<ffi.Char> split_path,
    int maxlen,
    ffi.Pointer<ffi.Char> path_prefix,
    int split_no,
    int split_count,
  ) {
    return _llama_split_path(
      split_path,
      maxlen,
      path_prefix,
      split_no,
      split_count,
    );
  }

  late final _llama_split_pathPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int Function(
            ffi.Pointer<ffi.Char>,
            ffi.Size,
            ffi.Pointer<ffi.Char>,
            ffi.Int,
            ffi.Int,
          )
        >
      >('llama_split_path');
  late final _llama_split_path = _llama_split_pathPtr
      .asFunction<
        int Function(
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<ffi.Char>,
          int,
          int,
        )
      >();

  /// @details Extract the path prefix from the split_path if and only if the split_no and split_count match.
  /// llama_split_prefix(split_prefix, 64, "/models/ggml-model-q4_0-00002-of-00004.gguf", 2, 4) => split_prefix = "/models/ggml-model-q4_0"
  int llama_split_prefix(
    ffi.Pointer<ffi.Char> split_prefix,
    int maxlen,
    ffi.Pointer<ffi.Char> split_path,
    int split_no,
    int split_count,
  ) {
    return _llama_split_prefix(
      split_prefix,
      maxlen,
      split_path,
      split_no,
      split_count,
    );
  }

  late final _llama_split_prefixPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int Function(
            ffi.Pointer<ffi.Char>,
            ffi.Size,
            ffi.Pointer<ffi.Char>,
            ffi.Int,
            ffi.Int,
          )
        >
      >('llama_split_prefix');
  late final _llama_split_prefix = _llama_split_prefixPtr
      .asFunction<
        int Function(
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<ffi.Char>,
          int,
          int,
        )
      >();

  ffi.Pointer<ffi.Char> llama_print_system_info() {
    return _llama_print_system_info();
  }

  late final _llama_print_system_infoPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'llama_print_system_info',
      );
  late final _llama_print_system_info = _llama_print_system_infoPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  void llama_log_set(
    ggml_log_callback log_callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _llama_log_set(log_callback, user_data);
  }

  late final _llama_log_setPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)
        >
      >('llama_log_set');
  late final _llama_log_set = _llama_log_setPtr
      .asFunction<void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>();

  llama_perf_context_data llama_perf_context(ffi.Pointer<llama_context> ctx) {
    return _llama_perf_context(ctx);
  }

  late final _llama_perf_contextPtr =
      _lookup<
        ffi.NativeFunction<
          llama_perf_context_data Function(ffi.Pointer<llama_context>)
        >
      >('llama_perf_context');
  late final _llama_perf_context = _llama_perf_contextPtr
      .asFunction<
        llama_perf_context_data Function(ffi.Pointer<llama_context>)
      >();

  void llama_perf_context_print(ffi.Pointer<llama_context> ctx) {
    return _llama_perf_context_print(ctx);
  }

  late final _llama_perf_context_printPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_perf_context_print');
  late final _llama_perf_context_print = _llama_perf_context_printPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  void llama_perf_context_reset(ffi.Pointer<llama_context> ctx) {
    return _llama_perf_context_reset(ctx);
  }

  late final _llama_perf_context_resetPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_perf_context_reset');
  late final _llama_perf_context_reset = _llama_perf_context_resetPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  llama_perf_sampler_data llama_perf_sampler(ffi.Pointer<llama_sampler> chain) {
    return _llama_perf_sampler(chain);
  }

  late final _llama_perf_samplerPtr =
      _lookup<
        ffi.NativeFunction<
          llama_perf_sampler_data Function(ffi.Pointer<llama_sampler>)
        >
      >('llama_perf_sampler');
  late final _llama_perf_sampler = _llama_perf_samplerPtr
      .asFunction<
        llama_perf_sampler_data Function(ffi.Pointer<llama_sampler>)
      >();

  void llama_perf_sampler_print(ffi.Pointer<llama_sampler> chain) {
    return _llama_perf_sampler_print(chain);
  }

  late final _llama_perf_sampler_printPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler>)>
      >('llama_perf_sampler_print');
  late final _llama_perf_sampler_print = _llama_perf_sampler_printPtr
      .asFunction<void Function(ffi.Pointer<llama_sampler>)>();

  void llama_perf_sampler_reset(ffi.Pointer<llama_sampler> chain) {
    return _llama_perf_sampler_reset(chain);
  }

  late final _llama_perf_sampler_resetPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler>)>
      >('llama_perf_sampler_reset');
  late final _llama_perf_sampler_reset = _llama_perf_sampler_resetPtr
      .asFunction<void Function(ffi.Pointer<llama_sampler>)>();

  void llama_memory_breakdown_print(ffi.Pointer<llama_context> ctx) {
    return _llama_memory_breakdown_print(ctx);
  }

  late final _llama_memory_breakdown_printPtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>
      >('llama_memory_breakdown_print');
  late final _llama_memory_breakdown_print = _llama_memory_breakdown_printPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  bool llama_opt_param_filter_all(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _llama_opt_param_filter_all(tensor, userdata);
  }

  late final _llama_opt_param_filter_allPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>)
        >
      >('llama_opt_param_filter_all');
  late final _llama_opt_param_filter_all = _llama_opt_param_filter_allPtr
      .asFunction<
        bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>)
      >();

  void llama_opt_init(
    ffi.Pointer<llama_context> lctx,
    ffi.Pointer<llama_model> model,
    llama_opt_params lopt_params,
  ) {
    return _llama_opt_init(lctx, model, lopt_params);
  }

  late final _llama_opt_initPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_context>,
            ffi.Pointer<llama_model>,
            llama_opt_params,
          )
        >
      >('llama_opt_init');
  late final _llama_opt_init = _llama_opt_initPtr
      .asFunction<
        void Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<llama_model>,
          llama_opt_params,
        )
      >();

  void llama_opt_epoch(
    ffi.Pointer<llama_context> lctx,
    ggml_opt_dataset_t dataset,
    ggml_opt_result_t result_train,
    ggml_opt_result_t result_eval,
    int idata_split,
    ggml_opt_epoch_callback callback_train,
    ggml_opt_epoch_callback callback_eval,
  ) {
    return _llama_opt_epoch(
      lctx,
      dataset,
      result_train,
      result_eval,
      idata_split,
      callback_train,
      callback_eval,
    );
  }

  late final _llama_opt_epochPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<llama_context>,
            ggml_opt_dataset_t,
            ggml_opt_result_t,
            ggml_opt_result_t,
            ffi.Int64,
            ggml_opt_epoch_callback,
            ggml_opt_epoch_callback,
          )
        >
      >('llama_opt_epoch');
  late final _llama_opt_epoch = _llama_opt_epochPtr
      .asFunction<
        void Function(
          ffi.Pointer<llama_context>,
          ggml_opt_dataset_t,
          ggml_opt_result_t,
          ggml_opt_result_t,
          int,
          ggml_opt_epoch_callback,
          ggml_opt_epoch_callback,
        )
      >();
}

final class llama_vocab extends ffi.Opaque {}

final class llama_model extends ffi.Opaque {}

final class llama_context extends ffi.Opaque {}

typedef llama_token = ffi.Int32;
typedef Dartllama_token = int;

final class llama_token_data extends ffi.Struct {
  @llama_token()
  external int id;

  @ffi.Float()
  external double logit;

  @ffi.Float()
  external double p;
}

final class llama_token_data_array extends ffi.Struct {
  external ffi.Pointer<llama_token_data> data;

  @ffi.Size()
  external int size;

  @ffi.Int64()
  external int selected;

  @ffi.Bool()
  external bool sorted;
}

final class llama_sampler_i extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_sampler> smpl)
    >
  >
  name;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(ffi.Pointer<llama_sampler> smpl, llama_token token)
    >
  >
  accept;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<llama_sampler> smpl,
        ffi.Pointer<llama_token_data_array> cur_p,
      )
    >
  >
  apply;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler> smpl)>
  >
  reset;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler> smpl)
    >
  >
  clone;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler> smpl)>
  >
  free;
}

typedef llama_sampler_context_t = ffi.Pointer<ffi.Void>;

final class llama_sampler extends ffi.Struct {
  external ffi.Pointer<llama_sampler_i> iface;

  external llama_sampler_context_t ctx;
}

final class llama_memory_i extends ffi.Opaque {}

typedef llama_memory_t = ffi.Pointer<llama_memory_i>;
typedef llama_pos = ffi.Int32;
typedef Dartllama_pos = int;
typedef llama_seq_id = ffi.Int32;
typedef Dartllama_seq_id = int;

enum llama_vocab_type {
  LLAMA_VOCAB_TYPE_NONE(0),
  LLAMA_VOCAB_TYPE_SPM(1),
  LLAMA_VOCAB_TYPE_BPE(2),
  LLAMA_VOCAB_TYPE_WPM(3),
  LLAMA_VOCAB_TYPE_UGM(4),
  LLAMA_VOCAB_TYPE_RWKV(5),
  LLAMA_VOCAB_TYPE_PLAMO2(6);

  final int value;
  const llama_vocab_type(this.value);

  static llama_vocab_type fromValue(int value) => switch (value) {
    0 => LLAMA_VOCAB_TYPE_NONE,
    1 => LLAMA_VOCAB_TYPE_SPM,
    2 => LLAMA_VOCAB_TYPE_BPE,
    3 => LLAMA_VOCAB_TYPE_WPM,
    4 => LLAMA_VOCAB_TYPE_UGM,
    5 => LLAMA_VOCAB_TYPE_RWKV,
    6 => LLAMA_VOCAB_TYPE_PLAMO2,
    _ => throw ArgumentError('Unknown value for llama_vocab_type: $value'),
  };
}

enum llama_rope_type {
  LLAMA_ROPE_TYPE_NONE(-1),
  LLAMA_ROPE_TYPE_NORM(0),
  LLAMA_ROPE_TYPE_NEOX(2),
  LLAMA_ROPE_TYPE_MROPE(8),
  LLAMA_ROPE_TYPE_VISION(24);

  final int value;
  const llama_rope_type(this.value);

  static llama_rope_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ROPE_TYPE_NONE,
    0 => LLAMA_ROPE_TYPE_NORM,
    2 => LLAMA_ROPE_TYPE_NEOX,
    8 => LLAMA_ROPE_TYPE_MROPE,
    24 => LLAMA_ROPE_TYPE_VISION,
    _ => throw ArgumentError('Unknown value for llama_rope_type: $value'),
  };
}

enum llama_token_type {
  LLAMA_TOKEN_TYPE_UNDEFINED(0),
  LLAMA_TOKEN_TYPE_NORMAL(1),
  LLAMA_TOKEN_TYPE_UNKNOWN(2),
  LLAMA_TOKEN_TYPE_CONTROL(3),
  LLAMA_TOKEN_TYPE_USER_DEFINED(4),
  LLAMA_TOKEN_TYPE_UNUSED(5),
  LLAMA_TOKEN_TYPE_BYTE(6);

  final int value;
  const llama_token_type(this.value);

  static llama_token_type fromValue(int value) => switch (value) {
    0 => LLAMA_TOKEN_TYPE_UNDEFINED,
    1 => LLAMA_TOKEN_TYPE_NORMAL,
    2 => LLAMA_TOKEN_TYPE_UNKNOWN,
    3 => LLAMA_TOKEN_TYPE_CONTROL,
    4 => LLAMA_TOKEN_TYPE_USER_DEFINED,
    5 => LLAMA_TOKEN_TYPE_UNUSED,
    6 => LLAMA_TOKEN_TYPE_BYTE,
    _ => throw ArgumentError('Unknown value for llama_token_type: $value'),
  };
}

enum llama_token_attr {
  LLAMA_TOKEN_ATTR_UNDEFINED(0),
  LLAMA_TOKEN_ATTR_UNKNOWN(1),
  LLAMA_TOKEN_ATTR_UNUSED(2),
  LLAMA_TOKEN_ATTR_NORMAL(4),
  LLAMA_TOKEN_ATTR_CONTROL(8),
  LLAMA_TOKEN_ATTR_USER_DEFINED(16),
  LLAMA_TOKEN_ATTR_BYTE(32),
  LLAMA_TOKEN_ATTR_NORMALIZED(64),
  LLAMA_TOKEN_ATTR_LSTRIP(128),
  LLAMA_TOKEN_ATTR_RSTRIP(256),
  LLAMA_TOKEN_ATTR_SINGLE_WORD(512);

  final int value;
  const llama_token_attr(this.value);

  static llama_token_attr fromValue(int value) => switch (value) {
    0 => LLAMA_TOKEN_ATTR_UNDEFINED,
    1 => LLAMA_TOKEN_ATTR_UNKNOWN,
    2 => LLAMA_TOKEN_ATTR_UNUSED,
    4 => LLAMA_TOKEN_ATTR_NORMAL,
    8 => LLAMA_TOKEN_ATTR_CONTROL,
    16 => LLAMA_TOKEN_ATTR_USER_DEFINED,
    32 => LLAMA_TOKEN_ATTR_BYTE,
    64 => LLAMA_TOKEN_ATTR_NORMALIZED,
    128 => LLAMA_TOKEN_ATTR_LSTRIP,
    256 => LLAMA_TOKEN_ATTR_RSTRIP,
    512 => LLAMA_TOKEN_ATTR_SINGLE_WORD,
    _ => throw ArgumentError('Unknown value for llama_token_attr: $value'),
  };
}

enum llama_ftype {
  LLAMA_FTYPE_ALL_F32(0),
  LLAMA_FTYPE_MOSTLY_F16(1),
  LLAMA_FTYPE_MOSTLY_Q4_0(2),
  LLAMA_FTYPE_MOSTLY_Q4_1(3),
  LLAMA_FTYPE_MOSTLY_Q8_0(7),
  LLAMA_FTYPE_MOSTLY_Q5_0(8),
  LLAMA_FTYPE_MOSTLY_Q5_1(9),
  LLAMA_FTYPE_MOSTLY_Q2_K(10),
  LLAMA_FTYPE_MOSTLY_Q3_K_S(11),
  LLAMA_FTYPE_MOSTLY_Q3_K_M(12),
  LLAMA_FTYPE_MOSTLY_Q3_K_L(13),
  LLAMA_FTYPE_MOSTLY_Q4_K_S(14),
  LLAMA_FTYPE_MOSTLY_Q4_K_M(15),
  LLAMA_FTYPE_MOSTLY_Q5_K_S(16),
  LLAMA_FTYPE_MOSTLY_Q5_K_M(17),
  LLAMA_FTYPE_MOSTLY_Q6_K(18),
  LLAMA_FTYPE_MOSTLY_IQ2_XXS(19),
  LLAMA_FTYPE_MOSTLY_IQ2_XS(20),
  LLAMA_FTYPE_MOSTLY_Q2_K_S(21),
  LLAMA_FTYPE_MOSTLY_IQ3_XS(22),
  LLAMA_FTYPE_MOSTLY_IQ3_XXS(23),
  LLAMA_FTYPE_MOSTLY_IQ1_S(24),
  LLAMA_FTYPE_MOSTLY_IQ4_NL(25),
  LLAMA_FTYPE_MOSTLY_IQ3_S(26),
  LLAMA_FTYPE_MOSTLY_IQ3_M(27),
  LLAMA_FTYPE_MOSTLY_IQ2_S(28),
  LLAMA_FTYPE_MOSTLY_IQ2_M(29),
  LLAMA_FTYPE_MOSTLY_IQ4_XS(30),
  LLAMA_FTYPE_MOSTLY_IQ1_M(31),
  LLAMA_FTYPE_MOSTLY_BF16(32),
  LLAMA_FTYPE_MOSTLY_TQ1_0(36),
  LLAMA_FTYPE_MOSTLY_TQ2_0(37),
  LLAMA_FTYPE_MOSTLY_MXFP4_MOE(38),
  LLAMA_FTYPE_GUESSED(1024);

  final int value;
  const llama_ftype(this.value);

  static llama_ftype fromValue(int value) => switch (value) {
    0 => LLAMA_FTYPE_ALL_F32,
    1 => LLAMA_FTYPE_MOSTLY_F16,
    2 => LLAMA_FTYPE_MOSTLY_Q4_0,
    3 => LLAMA_FTYPE_MOSTLY_Q4_1,
    7 => LLAMA_FTYPE_MOSTLY_Q8_0,
    8 => LLAMA_FTYPE_MOSTLY_Q5_0,
    9 => LLAMA_FTYPE_MOSTLY_Q5_1,
    10 => LLAMA_FTYPE_MOSTLY_Q2_K,
    11 => LLAMA_FTYPE_MOSTLY_Q3_K_S,
    12 => LLAMA_FTYPE_MOSTLY_Q3_K_M,
    13 => LLAMA_FTYPE_MOSTLY_Q3_K_L,
    14 => LLAMA_FTYPE_MOSTLY_Q4_K_S,
    15 => LLAMA_FTYPE_MOSTLY_Q4_K_M,
    16 => LLAMA_FTYPE_MOSTLY_Q5_K_S,
    17 => LLAMA_FTYPE_MOSTLY_Q5_K_M,
    18 => LLAMA_FTYPE_MOSTLY_Q6_K,
    19 => LLAMA_FTYPE_MOSTLY_IQ2_XXS,
    20 => LLAMA_FTYPE_MOSTLY_IQ2_XS,
    21 => LLAMA_FTYPE_MOSTLY_Q2_K_S,
    22 => LLAMA_FTYPE_MOSTLY_IQ3_XS,
    23 => LLAMA_FTYPE_MOSTLY_IQ3_XXS,
    24 => LLAMA_FTYPE_MOSTLY_IQ1_S,
    25 => LLAMA_FTYPE_MOSTLY_IQ4_NL,
    26 => LLAMA_FTYPE_MOSTLY_IQ3_S,
    27 => LLAMA_FTYPE_MOSTLY_IQ3_M,
    28 => LLAMA_FTYPE_MOSTLY_IQ2_S,
    29 => LLAMA_FTYPE_MOSTLY_IQ2_M,
    30 => LLAMA_FTYPE_MOSTLY_IQ4_XS,
    31 => LLAMA_FTYPE_MOSTLY_IQ1_M,
    32 => LLAMA_FTYPE_MOSTLY_BF16,
    36 => LLAMA_FTYPE_MOSTLY_TQ1_0,
    37 => LLAMA_FTYPE_MOSTLY_TQ2_0,
    38 => LLAMA_FTYPE_MOSTLY_MXFP4_MOE,
    1024 => LLAMA_FTYPE_GUESSED,
    _ => throw ArgumentError('Unknown value for llama_ftype: $value'),
  };
}

enum llama_rope_scaling_type {
  LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED(-1),
  LLAMA_ROPE_SCALING_TYPE_NONE(0),
  LLAMA_ROPE_SCALING_TYPE_LINEAR(1),
  LLAMA_ROPE_SCALING_TYPE_YARN(2),
  LLAMA_ROPE_SCALING_TYPE_LONGROPE(3);

  static const LLAMA_ROPE_SCALING_TYPE_MAX_VALUE =
      LLAMA_ROPE_SCALING_TYPE_LONGROPE;

  final int value;
  const llama_rope_scaling_type(this.value);

  static llama_rope_scaling_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED,
    0 => LLAMA_ROPE_SCALING_TYPE_NONE,
    1 => LLAMA_ROPE_SCALING_TYPE_LINEAR,
    2 => LLAMA_ROPE_SCALING_TYPE_YARN,
    3 => LLAMA_ROPE_SCALING_TYPE_LONGROPE,
    _ => throw ArgumentError(
      'Unknown value for llama_rope_scaling_type: $value',
    ),
  };

  @override
  String toString() {
    if (this == LLAMA_ROPE_SCALING_TYPE_LONGROPE)
      return "llama_rope_scaling_type.LLAMA_ROPE_SCALING_TYPE_LONGROPE, llama_rope_scaling_type.LLAMA_ROPE_SCALING_TYPE_MAX_VALUE";
    return super.toString();
  }
}

enum llama_pooling_type {
  LLAMA_POOLING_TYPE_UNSPECIFIED(-1),
  LLAMA_POOLING_TYPE_NONE(0),
  LLAMA_POOLING_TYPE_MEAN(1),
  LLAMA_POOLING_TYPE_CLS(2),
  LLAMA_POOLING_TYPE_LAST(3),
  LLAMA_POOLING_TYPE_RANK(4);

  final int value;
  const llama_pooling_type(this.value);

  static llama_pooling_type fromValue(int value) => switch (value) {
    -1 => LLAMA_POOLING_TYPE_UNSPECIFIED,
    0 => LLAMA_POOLING_TYPE_NONE,
    1 => LLAMA_POOLING_TYPE_MEAN,
    2 => LLAMA_POOLING_TYPE_CLS,
    3 => LLAMA_POOLING_TYPE_LAST,
    4 => LLAMA_POOLING_TYPE_RANK,
    _ => throw ArgumentError('Unknown value for llama_pooling_type: $value'),
  };
}

enum llama_attention_type {
  LLAMA_ATTENTION_TYPE_UNSPECIFIED(-1),
  LLAMA_ATTENTION_TYPE_CAUSAL(0),
  LLAMA_ATTENTION_TYPE_NON_CAUSAL(1);

  final int value;
  const llama_attention_type(this.value);

  static llama_attention_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ATTENTION_TYPE_UNSPECIFIED,
    0 => LLAMA_ATTENTION_TYPE_CAUSAL,
    1 => LLAMA_ATTENTION_TYPE_NON_CAUSAL,
    _ => throw ArgumentError('Unknown value for llama_attention_type: $value'),
  };
}

enum llama_flash_attn_type {
  LLAMA_FLASH_ATTN_TYPE_AUTO(-1),
  LLAMA_FLASH_ATTN_TYPE_DISABLED(0),
  LLAMA_FLASH_ATTN_TYPE_ENABLED(1);

  final int value;
  const llama_flash_attn_type(this.value);

  static llama_flash_attn_type fromValue(int value) => switch (value) {
    -1 => LLAMA_FLASH_ATTN_TYPE_AUTO,
    0 => LLAMA_FLASH_ATTN_TYPE_DISABLED,
    1 => LLAMA_FLASH_ATTN_TYPE_ENABLED,
    _ => throw ArgumentError('Unknown value for llama_flash_attn_type: $value'),
  };
}

enum llama_split_mode {
  LLAMA_SPLIT_MODE_NONE(0),
  LLAMA_SPLIT_MODE_LAYER(1),
  LLAMA_SPLIT_MODE_ROW(2);

  final int value;
  const llama_split_mode(this.value);

  static llama_split_mode fromValue(int value) => switch (value) {
    0 => LLAMA_SPLIT_MODE_NONE,
    1 => LLAMA_SPLIT_MODE_LAYER,
    2 => LLAMA_SPLIT_MODE_ROW,
    _ => throw ArgumentError('Unknown value for llama_split_mode: $value'),
  };
}

typedef llama_progress_callbackFunction =
    ffi.Bool Function(ffi.Float progress, ffi.Pointer<ffi.Void> user_data);
typedef Dartllama_progress_callbackFunction =
    bool Function(double progress, ffi.Pointer<ffi.Void> user_data);
typedef llama_progress_callback =
    ffi.Pointer<ffi.NativeFunction<llama_progress_callbackFunction>>;

final class llama_batch extends ffi.Struct {
  @ffi.Int32()
  external int n_tokens;

  external ffi.Pointer<llama_token> token;

  external ffi.Pointer<ffi.Float> embd;

  external ffi.Pointer<llama_pos> pos;

  external ffi.Pointer<ffi.Int32> n_seq_id;

  external ffi.Pointer<ffi.Pointer<llama_seq_id>> seq_id;

  external ffi.Pointer<ffi.Int8> logits;
}

enum llama_model_kv_override_type {
  LLAMA_KV_OVERRIDE_TYPE_INT(0),
  LLAMA_KV_OVERRIDE_TYPE_FLOAT(1),
  LLAMA_KV_OVERRIDE_TYPE_BOOL(2),
  LLAMA_KV_OVERRIDE_TYPE_STR(3);

  final int value;
  const llama_model_kv_override_type(this.value);

  static llama_model_kv_override_type fromValue(int value) => switch (value) {
    0 => LLAMA_KV_OVERRIDE_TYPE_INT,
    1 => LLAMA_KV_OVERRIDE_TYPE_FLOAT,
    2 => LLAMA_KV_OVERRIDE_TYPE_BOOL,
    3 => LLAMA_KV_OVERRIDE_TYPE_STR,
    _ => throw ArgumentError(
      'Unknown value for llama_model_kv_override_type: $value',
    ),
  };
}

final class UnnamedUnion1 extends ffi.Union {
  @ffi.Int64()
  external int val_i64;

  @ffi.Double()
  external double val_f64;

  @ffi.Bool()
  external bool val_bool;

  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> val_str;
}

final class llama_model_kv_override extends ffi.Struct {
  @ffi.UnsignedInt()
  external int tagAsInt;

  llama_model_kv_override_type get tag =>
      llama_model_kv_override_type.fromValue(tagAsInt);

  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> key;

  external UnnamedUnion1 unnamed;
}

final class ggml_backend_buffer_type extends ffi.Opaque {}

typedef ggml_backend_buffer_type_t = ffi.Pointer<ggml_backend_buffer_type>;

final class llama_model_tensor_buft_override extends ffi.Struct {
  external ffi.Pointer<ffi.Char> pattern;

  external ggml_backend_buffer_type_t buft;
}

final class ggml_backend_device extends ffi.Opaque {}

typedef ggml_backend_dev_t = ffi.Pointer<ggml_backend_device>;

final class llama_model_params extends ffi.Struct {
  external ffi.Pointer<ggml_backend_dev_t> devices;

  external ffi.Pointer<llama_model_tensor_buft_override> tensor_buft_overrides;

  @ffi.Int32()
  external int n_gpu_layers;

  @ffi.UnsignedInt()
  external int split_modeAsInt;

  llama_split_mode get split_mode =>
      llama_split_mode.fromValue(split_modeAsInt);

  @ffi.Int32()
  external int main_gpu;

  external ffi.Pointer<ffi.Float> tensor_split;

  external llama_progress_callback progress_callback;

  external ffi.Pointer<ffi.Void> progress_callback_user_data;

  external ffi.Pointer<llama_model_kv_override> kv_overrides;

  @ffi.Bool()
  external bool vocab_only;

  @ffi.Bool()
  external bool use_mmap;

  @ffi.Bool()
  external bool use_mlock;

  @ffi.Bool()
  external bool check_tensors;

  @ffi.Bool()
  external bool use_extra_bufts;

  @ffi.Bool()
  external bool no_host;
}

enum ggml_type {
  GGML_TYPE_F32(0),
  GGML_TYPE_F16(1),
  GGML_TYPE_Q4_0(2),
  GGML_TYPE_Q4_1(3),
  GGML_TYPE_Q5_0(6),
  GGML_TYPE_Q5_1(7),
  GGML_TYPE_Q8_0(8),
  GGML_TYPE_Q8_1(9),
  GGML_TYPE_Q2_K(10),
  GGML_TYPE_Q3_K(11),
  GGML_TYPE_Q4_K(12),
  GGML_TYPE_Q5_K(13),
  GGML_TYPE_Q6_K(14),
  GGML_TYPE_Q8_K(15),
  GGML_TYPE_IQ2_XXS(16),
  GGML_TYPE_IQ2_XS(17),
  GGML_TYPE_IQ3_XXS(18),
  GGML_TYPE_IQ1_S(19),
  GGML_TYPE_IQ4_NL(20),
  GGML_TYPE_IQ3_S(21),
  GGML_TYPE_IQ2_S(22),
  GGML_TYPE_IQ4_XS(23),
  GGML_TYPE_I8(24),
  GGML_TYPE_I16(25),
  GGML_TYPE_I32(26),
  GGML_TYPE_I64(27),
  GGML_TYPE_F64(28),
  GGML_TYPE_IQ1_M(29),
  GGML_TYPE_BF16(30),
  GGML_TYPE_TQ1_0(34),
  GGML_TYPE_TQ2_0(35),
  GGML_TYPE_MXFP4(39),
  GGML_TYPE_COUNT(40);

  final int value;
  const ggml_type(this.value);

  static ggml_type fromValue(int value) => switch (value) {
    0 => GGML_TYPE_F32,
    1 => GGML_TYPE_F16,
    2 => GGML_TYPE_Q4_0,
    3 => GGML_TYPE_Q4_1,
    6 => GGML_TYPE_Q5_0,
    7 => GGML_TYPE_Q5_1,
    8 => GGML_TYPE_Q8_0,
    9 => GGML_TYPE_Q8_1,
    10 => GGML_TYPE_Q2_K,
    11 => GGML_TYPE_Q3_K,
    12 => GGML_TYPE_Q4_K,
    13 => GGML_TYPE_Q5_K,
    14 => GGML_TYPE_Q6_K,
    15 => GGML_TYPE_Q8_K,
    16 => GGML_TYPE_IQ2_XXS,
    17 => GGML_TYPE_IQ2_XS,
    18 => GGML_TYPE_IQ3_XXS,
    19 => GGML_TYPE_IQ1_S,
    20 => GGML_TYPE_IQ4_NL,
    21 => GGML_TYPE_IQ3_S,
    22 => GGML_TYPE_IQ2_S,
    23 => GGML_TYPE_IQ4_XS,
    24 => GGML_TYPE_I8,
    25 => GGML_TYPE_I16,
    26 => GGML_TYPE_I32,
    27 => GGML_TYPE_I64,
    28 => GGML_TYPE_F64,
    29 => GGML_TYPE_IQ1_M,
    30 => GGML_TYPE_BF16,
    34 => GGML_TYPE_TQ1_0,
    35 => GGML_TYPE_TQ2_0,
    39 => GGML_TYPE_MXFP4,
    40 => GGML_TYPE_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_type: $value'),
  };
}

final class ggml_backend_buffer extends ffi.Opaque {}

enum ggml_op {
  GGML_OP_NONE(0),
  GGML_OP_DUP(1),
  GGML_OP_ADD(2),
  GGML_OP_ADD_ID(3),
  GGML_OP_ADD1(4),
  GGML_OP_ACC(5),
  GGML_OP_SUB(6),
  GGML_OP_MUL(7),
  GGML_OP_DIV(8),
  GGML_OP_SQR(9),
  GGML_OP_SQRT(10),
  GGML_OP_LOG(11),
  GGML_OP_SIN(12),
  GGML_OP_COS(13),
  GGML_OP_SUM(14),
  GGML_OP_SUM_ROWS(15),
  GGML_OP_MEAN(16),
  GGML_OP_ARGMAX(17),
  GGML_OP_COUNT_EQUAL(18),
  GGML_OP_REPEAT(19),
  GGML_OP_REPEAT_BACK(20),
  GGML_OP_CONCAT(21),
  GGML_OP_SILU_BACK(22),
  GGML_OP_NORM(23),
  GGML_OP_RMS_NORM(24),
  GGML_OP_RMS_NORM_BACK(25),
  GGML_OP_GROUP_NORM(26),
  GGML_OP_L2_NORM(27),
  GGML_OP_MUL_MAT(28),
  GGML_OP_MUL_MAT_ID(29),
  GGML_OP_OUT_PROD(30),
  GGML_OP_SCALE(31),
  GGML_OP_SET(32),
  GGML_OP_CPY(33),
  GGML_OP_CONT(34),
  GGML_OP_RESHAPE(35),
  GGML_OP_VIEW(36),
  GGML_OP_PERMUTE(37),
  GGML_OP_TRANSPOSE(38),
  GGML_OP_GET_ROWS(39),
  GGML_OP_GET_ROWS_BACK(40),
  GGML_OP_SET_ROWS(41),
  GGML_OP_DIAG(42),
  GGML_OP_DIAG_MASK_INF(43),
  GGML_OP_DIAG_MASK_ZERO(44),
  GGML_OP_SOFT_MAX(45),
  GGML_OP_SOFT_MAX_BACK(46),
  GGML_OP_ROPE(47),
  GGML_OP_ROPE_BACK(48),
  GGML_OP_CLAMP(49),
  GGML_OP_CONV_TRANSPOSE_1D(50),
  GGML_OP_IM2COL(51),
  GGML_OP_IM2COL_BACK(52),
  GGML_OP_IM2COL_3D(53),
  GGML_OP_CONV_2D(54),
  GGML_OP_CONV_3D(55),
  GGML_OP_CONV_2D_DW(56),
  GGML_OP_CONV_TRANSPOSE_2D(57),
  GGML_OP_POOL_1D(58),
  GGML_OP_POOL_2D(59),
  GGML_OP_POOL_2D_BACK(60),
  GGML_OP_UPSCALE(61),
  GGML_OP_PAD(62),
  GGML_OP_PAD_REFLECT_1D(63),
  GGML_OP_ROLL(64),
  GGML_OP_ARANGE(65),
  GGML_OP_TIMESTEP_EMBEDDING(66),
  GGML_OP_ARGSORT(67),
  GGML_OP_LEAKY_RELU(68),
  GGML_OP_FLASH_ATTN_EXT(69),
  GGML_OP_FLASH_ATTN_BACK(70),
  GGML_OP_SSM_CONV(71),
  GGML_OP_SSM_SCAN(72),
  GGML_OP_WIN_PART(73),
  GGML_OP_WIN_UNPART(74),
  GGML_OP_GET_REL_POS(75),
  GGML_OP_ADD_REL_POS(76),
  GGML_OP_RWKV_WKV6(77),
  GGML_OP_GATED_LINEAR_ATTN(78),
  GGML_OP_RWKV_WKV7(79),
  GGML_OP_UNARY(80),
  GGML_OP_MAP_CUSTOM1(81),
  GGML_OP_MAP_CUSTOM2(82),
  GGML_OP_MAP_CUSTOM3(83),
  GGML_OP_CUSTOM(84),
  GGML_OP_CROSS_ENTROPY_LOSS(85),
  GGML_OP_CROSS_ENTROPY_LOSS_BACK(86),
  GGML_OP_OPT_STEP_ADAMW(87),
  GGML_OP_OPT_STEP_SGD(88),
  GGML_OP_GLU(89),
  GGML_OP_COUNT(90);

  final int value;
  const ggml_op(this.value);

  static ggml_op fromValue(int value) => switch (value) {
    0 => GGML_OP_NONE,
    1 => GGML_OP_DUP,
    2 => GGML_OP_ADD,
    3 => GGML_OP_ADD_ID,
    4 => GGML_OP_ADD1,
    5 => GGML_OP_ACC,
    6 => GGML_OP_SUB,
    7 => GGML_OP_MUL,
    8 => GGML_OP_DIV,
    9 => GGML_OP_SQR,
    10 => GGML_OP_SQRT,
    11 => GGML_OP_LOG,
    12 => GGML_OP_SIN,
    13 => GGML_OP_COS,
    14 => GGML_OP_SUM,
    15 => GGML_OP_SUM_ROWS,
    16 => GGML_OP_MEAN,
    17 => GGML_OP_ARGMAX,
    18 => GGML_OP_COUNT_EQUAL,
    19 => GGML_OP_REPEAT,
    20 => GGML_OP_REPEAT_BACK,
    21 => GGML_OP_CONCAT,
    22 => GGML_OP_SILU_BACK,
    23 => GGML_OP_NORM,
    24 => GGML_OP_RMS_NORM,
    25 => GGML_OP_RMS_NORM_BACK,
    26 => GGML_OP_GROUP_NORM,
    27 => GGML_OP_L2_NORM,
    28 => GGML_OP_MUL_MAT,
    29 => GGML_OP_MUL_MAT_ID,
    30 => GGML_OP_OUT_PROD,
    31 => GGML_OP_SCALE,
    32 => GGML_OP_SET,
    33 => GGML_OP_CPY,
    34 => GGML_OP_CONT,
    35 => GGML_OP_RESHAPE,
    36 => GGML_OP_VIEW,
    37 => GGML_OP_PERMUTE,
    38 => GGML_OP_TRANSPOSE,
    39 => GGML_OP_GET_ROWS,
    40 => GGML_OP_GET_ROWS_BACK,
    41 => GGML_OP_SET_ROWS,
    42 => GGML_OP_DIAG,
    43 => GGML_OP_DIAG_MASK_INF,
    44 => GGML_OP_DIAG_MASK_ZERO,
    45 => GGML_OP_SOFT_MAX,
    46 => GGML_OP_SOFT_MAX_BACK,
    47 => GGML_OP_ROPE,
    48 => GGML_OP_ROPE_BACK,
    49 => GGML_OP_CLAMP,
    50 => GGML_OP_CONV_TRANSPOSE_1D,
    51 => GGML_OP_IM2COL,
    52 => GGML_OP_IM2COL_BACK,
    53 => GGML_OP_IM2COL_3D,
    54 => GGML_OP_CONV_2D,
    55 => GGML_OP_CONV_3D,
    56 => GGML_OP_CONV_2D_DW,
    57 => GGML_OP_CONV_TRANSPOSE_2D,
    58 => GGML_OP_POOL_1D,
    59 => GGML_OP_POOL_2D,
    60 => GGML_OP_POOL_2D_BACK,
    61 => GGML_OP_UPSCALE,
    62 => GGML_OP_PAD,
    63 => GGML_OP_PAD_REFLECT_1D,
    64 => GGML_OP_ROLL,
    65 => GGML_OP_ARANGE,
    66 => GGML_OP_TIMESTEP_EMBEDDING,
    67 => GGML_OP_ARGSORT,
    68 => GGML_OP_LEAKY_RELU,
    69 => GGML_OP_FLASH_ATTN_EXT,
    70 => GGML_OP_FLASH_ATTN_BACK,
    71 => GGML_OP_SSM_CONV,
    72 => GGML_OP_SSM_SCAN,
    73 => GGML_OP_WIN_PART,
    74 => GGML_OP_WIN_UNPART,
    75 => GGML_OP_GET_REL_POS,
    76 => GGML_OP_ADD_REL_POS,
    77 => GGML_OP_RWKV_WKV6,
    78 => GGML_OP_GATED_LINEAR_ATTN,
    79 => GGML_OP_RWKV_WKV7,
    80 => GGML_OP_UNARY,
    81 => GGML_OP_MAP_CUSTOM1,
    82 => GGML_OP_MAP_CUSTOM2,
    83 => GGML_OP_MAP_CUSTOM3,
    84 => GGML_OP_CUSTOM,
    85 => GGML_OP_CROSS_ENTROPY_LOSS,
    86 => GGML_OP_CROSS_ENTROPY_LOSS_BACK,
    87 => GGML_OP_OPT_STEP_ADAMW,
    88 => GGML_OP_OPT_STEP_SGD,
    89 => GGML_OP_GLU,
    90 => GGML_OP_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_op: $value'),
  };
}

final class ggml_tensor extends ffi.Struct {
  @ffi.UnsignedInt()
  external int typeAsInt;

  ggml_type get type => ggml_type.fromValue(typeAsInt);

  external ffi.Pointer<ggml_backend_buffer> buffer;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> ne;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Size> nb;

  @ffi.UnsignedInt()
  external int opAsInt;

  ggml_op get op => ggml_op.fromValue(opAsInt);

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int32> op_params;

  @ffi.Int32()
  external int flags;

  @ffi.Array.multi([10])
  external ffi.Array<ffi.Pointer<ggml_tensor>> src;

  external ffi.Pointer<ggml_tensor> view_src;

  @ffi.Size()
  external int view_offs;

  external ffi.Pointer<ffi.Void> data;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> name;

  external ffi.Pointer<ffi.Void> extra;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> padding;
}

typedef ggml_backend_sched_eval_callbackFunction =
    ffi.Bool Function(
      ffi.Pointer<ggml_tensor> t,
      ffi.Bool ask,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef Dartggml_backend_sched_eval_callbackFunction =
    bool Function(
      ffi.Pointer<ggml_tensor> t,
      bool ask,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef ggml_backend_sched_eval_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_sched_eval_callbackFunction>>;
typedef ggml_abort_callbackFunction =
    ffi.Bool Function(ffi.Pointer<ffi.Void> data);
typedef Dartggml_abort_callbackFunction =
    bool Function(ffi.Pointer<ffi.Void> data);
typedef ggml_abort_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_abort_callbackFunction>>;

final class llama_context_params extends ffi.Struct {
  @ffi.Uint32()
  external int n_ctx;

  @ffi.Uint32()
  external int n_batch;

  @ffi.Uint32()
  external int n_ubatch;

  @ffi.Uint32()
  external int n_seq_max;

  @ffi.Int32()
  external int n_threads;

  @ffi.Int32()
  external int n_threads_batch;

  @ffi.Int()
  external int rope_scaling_typeAsInt;

  llama_rope_scaling_type get rope_scaling_type =>
      llama_rope_scaling_type.fromValue(rope_scaling_typeAsInt);

  @ffi.Int()
  external int pooling_typeAsInt;

  llama_pooling_type get pooling_type =>
      llama_pooling_type.fromValue(pooling_typeAsInt);

  @ffi.Int()
  external int attention_typeAsInt;

  llama_attention_type get attention_type =>
      llama_attention_type.fromValue(attention_typeAsInt);

  @ffi.Int()
  external int flash_attn_typeAsInt;

  llama_flash_attn_type get flash_attn_type =>
      llama_flash_attn_type.fromValue(flash_attn_typeAsInt);

  @ffi.Float()
  external double rope_freq_base;

  @ffi.Float()
  external double rope_freq_scale;

  @ffi.Float()
  external double yarn_ext_factor;

  @ffi.Float()
  external double yarn_attn_factor;

  @ffi.Float()
  external double yarn_beta_fast;

  @ffi.Float()
  external double yarn_beta_slow;

  @ffi.Uint32()
  external int yarn_orig_ctx;

  @ffi.Float()
  external double defrag_thold;

  external ggml_backend_sched_eval_callback cb_eval;

  external ffi.Pointer<ffi.Void> cb_eval_user_data;

  @ffi.UnsignedInt()
  external int type_kAsInt;

  ggml_type get type_k => ggml_type.fromValue(type_kAsInt);

  @ffi.UnsignedInt()
  external int type_vAsInt;

  ggml_type get type_v => ggml_type.fromValue(type_vAsInt);

  external ggml_abort_callback abort_callback;

  external ffi.Pointer<ffi.Void> abort_callback_data;

  @ffi.Bool()
  external bool embeddings;

  @ffi.Bool()
  external bool offload_kqv;

  @ffi.Bool()
  external bool no_perf;

  @ffi.Bool()
  external bool op_offload;

  @ffi.Bool()
  external bool swa_full;

  @ffi.Bool()
  external bool kv_unified;
}

final class llama_model_quantize_params extends ffi.Struct {
  @ffi.Int32()
  external int nthread;

  @ffi.UnsignedInt()
  external int ftypeAsInt;

  llama_ftype get ftype => llama_ftype.fromValue(ftypeAsInt);

  @ffi.UnsignedInt()
  external int output_tensor_typeAsInt;

  ggml_type get output_tensor_type =>
      ggml_type.fromValue(output_tensor_typeAsInt);

  @ffi.UnsignedInt()
  external int token_embedding_typeAsInt;

  ggml_type get token_embedding_type =>
      ggml_type.fromValue(token_embedding_typeAsInt);

  @ffi.Bool()
  external bool allow_requantize;

  @ffi.Bool()
  external bool quantize_output_tensor;

  @ffi.Bool()
  external bool only_copy;

  @ffi.Bool()
  external bool pure;

  @ffi.Bool()
  external bool keep_split;

  external ffi.Pointer<ffi.Void> imatrix;

  external ffi.Pointer<ffi.Void> kv_overrides;

  external ffi.Pointer<ffi.Void> tensor_types;

  external ffi.Pointer<ffi.Void> prune_layers;
}

final class llama_logit_bias extends ffi.Struct {
  @llama_token()
  external int token;

  @ffi.Float()
  external double bias;
}

final class llama_sampler_chain_params extends ffi.Struct {
  @ffi.Bool()
  external bool no_perf;
}

final class llama_chat_message extends ffi.Struct {
  external ffi.Pointer<ffi.Char> role;

  external ffi.Pointer<ffi.Char> content;
}

final class llama_adapter_lora extends ffi.Opaque {}

enum ggml_numa_strategy {
  GGML_NUMA_STRATEGY_DISABLED(0),
  GGML_NUMA_STRATEGY_DISTRIBUTE(1),
  GGML_NUMA_STRATEGY_ISOLATE(2),
  GGML_NUMA_STRATEGY_NUMACTL(3),
  GGML_NUMA_STRATEGY_MIRROR(4),
  GGML_NUMA_STRATEGY_COUNT(5);

  final int value;
  const ggml_numa_strategy(this.value);

  static ggml_numa_strategy fromValue(int value) => switch (value) {
    0 => GGML_NUMA_STRATEGY_DISABLED,
    1 => GGML_NUMA_STRATEGY_DISTRIBUTE,
    2 => GGML_NUMA_STRATEGY_ISOLATE,
    3 => GGML_NUMA_STRATEGY_NUMACTL,
    4 => GGML_NUMA_STRATEGY_MIRROR,
    5 => GGML_NUMA_STRATEGY_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_numa_strategy: $value'),
  };
}

final class ggml_threadpool extends ffi.Opaque {}

typedef ggml_threadpool_t = ffi.Pointer<ggml_threadpool>;
typedef llama_state_seq_flags = ffi.Uint32;
typedef Dartllama_state_seq_flags = int;

enum ggml_log_level {
  GGML_LOG_LEVEL_NONE(0),
  GGML_LOG_LEVEL_DEBUG(1),
  GGML_LOG_LEVEL_INFO(2),
  GGML_LOG_LEVEL_WARN(3),
  GGML_LOG_LEVEL_ERROR(4),
  GGML_LOG_LEVEL_CONT(5);

  final int value;
  const ggml_log_level(this.value);

  static ggml_log_level fromValue(int value) => switch (value) {
    0 => GGML_LOG_LEVEL_NONE,
    1 => GGML_LOG_LEVEL_DEBUG,
    2 => GGML_LOG_LEVEL_INFO,
    3 => GGML_LOG_LEVEL_WARN,
    4 => GGML_LOG_LEVEL_ERROR,
    5 => GGML_LOG_LEVEL_CONT,
    _ => throw ArgumentError('Unknown value for ggml_log_level: $value'),
  };
}

typedef ggml_log_callbackFunction =
    ffi.Void Function(
      ffi.UnsignedInt level,
      ffi.Pointer<ffi.Char> text,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef Dartggml_log_callbackFunction =
    void Function(
      ggml_log_level level,
      ffi.Pointer<ffi.Char> text,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef ggml_log_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_log_callbackFunction>>;

final class llama_perf_context_data extends ffi.Struct {
  @ffi.Double()
  external double t_start_ms;

  @ffi.Double()
  external double t_load_ms;

  @ffi.Double()
  external double t_p_eval_ms;

  @ffi.Double()
  external double t_eval_ms;

  @ffi.Int32()
  external int n_p_eval;

  @ffi.Int32()
  external int n_eval;

  @ffi.Int32()
  external int n_reused;
}

final class llama_perf_sampler_data extends ffi.Struct {
  @ffi.Double()
  external double t_sample_ms;

  @ffi.Int32()
  external int n_sample;
}

typedef llama_opt_param_filterFunction =
    ffi.Bool Function(
      ffi.Pointer<ggml_tensor> tensor,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartllama_opt_param_filterFunction =
    bool Function(
      ffi.Pointer<ggml_tensor> tensor,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef llama_opt_param_filter =
    ffi.Pointer<ffi.NativeFunction<llama_opt_param_filterFunction>>;

final class UnnamedStruct1 extends ffi.Struct {
  @ffi.Float()
  external double alpha;

  @ffi.Float()
  external double beta1;

  @ffi.Float()
  external double beta2;

  @ffi.Float()
  external double eps;

  @ffi.Float()
  external double wd;
}

final class UnnamedStruct2 extends ffi.Struct {
  @ffi.Float()
  external double alpha;

  @ffi.Float()
  external double wd;
}

final class ggml_opt_optimizer_params extends ffi.Struct {
  external UnnamedStruct1 adamw;

  external UnnamedStruct2 sgd;
}

typedef ggml_opt_get_optimizer_paramsFunction =
    ggml_opt_optimizer_params Function(ffi.Pointer<ffi.Void> userdata);
typedef ggml_opt_get_optimizer_params =
    ffi.Pointer<ffi.NativeFunction<ggml_opt_get_optimizer_paramsFunction>>;

enum ggml_opt_optimizer_type {
  GGML_OPT_OPTIMIZER_TYPE_ADAMW(0),
  GGML_OPT_OPTIMIZER_TYPE_SGD(1),
  GGML_OPT_OPTIMIZER_TYPE_COUNT(2);

  final int value;
  const ggml_opt_optimizer_type(this.value);

  static ggml_opt_optimizer_type fromValue(int value) => switch (value) {
    0 => GGML_OPT_OPTIMIZER_TYPE_ADAMW,
    1 => GGML_OPT_OPTIMIZER_TYPE_SGD,
    2 => GGML_OPT_OPTIMIZER_TYPE_COUNT,
    _ => throw ArgumentError(
      'Unknown value for ggml_opt_optimizer_type: $value',
    ),
  };
}

final class llama_opt_params extends ffi.Struct {
  @ffi.Uint32()
  external int n_ctx_train;

  external llama_opt_param_filter param_filter;

  external ffi.Pointer<ffi.Void> param_filter_ud;

  external ggml_opt_get_optimizer_params get_opt_pars;

  external ffi.Pointer<ffi.Void> get_opt_pars_ud;

  @ffi.UnsignedInt()
  external int optimizer_typeAsInt;

  ggml_opt_optimizer_type get optimizer_type =>
      ggml_opt_optimizer_type.fromValue(optimizer_typeAsInt);
}

final class ggml_opt_dataset extends ffi.Opaque {}

typedef ggml_opt_dataset_t = ffi.Pointer<ggml_opt_dataset>;

final class ggml_opt_result extends ffi.Opaque {}

typedef ggml_opt_result_t = ffi.Pointer<ggml_opt_result>;

final class ggml_opt_context extends ffi.Opaque {}

typedef ggml_opt_context_t = ffi.Pointer<ggml_opt_context>;
typedef ggml_opt_epoch_callbackFunction =
    ffi.Void Function(
      ffi.Bool train,
      ggml_opt_context_t opt_ctx,
      ggml_opt_dataset_t dataset,
      ggml_opt_result_t result,
      ffi.Int64 ibatch,
      ffi.Int64 ibatch_max,
      ffi.Int64 t_start_us,
    );
typedef Dartggml_opt_epoch_callbackFunction =
    void Function(
      bool train,
      ggml_opt_context_t opt_ctx,
      ggml_opt_dataset_t dataset,
      ggml_opt_result_t result,
      int ibatch,
      int ibatch_max,
      int t_start_us,
    );
typedef ggml_opt_epoch_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_opt_epoch_callbackFunction>>;

const int LLAMA_DEFAULT_SEED = 4294967295;

const int LLAMA_TOKEN_NULL = -1;

const int LLAMA_FILE_MAGIC_GGLA = 1734831201;

const int LLAMA_FILE_MAGIC_GGSN = 1734833006;

const int LLAMA_FILE_MAGIC_GGSQ = 1734833009;

const int LLAMA_SESSION_MAGIC = 1734833006;

const int LLAMA_SESSION_VERSION = 9;

const int LLAMA_STATE_SEQ_MAGIC = 1734833009;

const int LLAMA_STATE_SEQ_VERSION = 2;

const int LLAMA_STATE_SEQ_FLAGS_SWA_ONLY = 1;

const int LLAMA_STATE_SEQ_FLAGS_PARTIAL_ONLY = 1;
